{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82cbbf0fcfaf46e0bca93455b8acb8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ba668b67e7f46d684138c617aa6b5de",
              "IPY_MODEL_c66c9508e53e48ef9592d8dfa20f1cd2",
              "IPY_MODEL_57e51658cbf34ec1957af0eed79c71b6"
            ],
            "layout": "IPY_MODEL_87794392f0b64768a313090ee0353e5a"
          }
        },
        "6ba668b67e7f46d684138c617aa6b5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c15711c76414fca95a64cae87f38b24",
            "placeholder": "​",
            "style": "IPY_MODEL_a43dcdd40c7547a0b564b11800703893",
            "value": ""
          }
        },
        "c66c9508e53e48ef9592d8dfa20f1cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4828e52b8b18470298c8d9c5e18b2e95",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_feb8b2e1d72945b4aa3d72720334c2ae",
            "value": 0
          }
        },
        "57e51658cbf34ec1957af0eed79c71b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae2e68826f314d31b0fa5e9bafe5e695",
            "placeholder": "​",
            "style": "IPY_MODEL_914a052327d3449b9415540ba42e78f9",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "87794392f0b64768a313090ee0353e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c15711c76414fca95a64cae87f38b24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a43dcdd40c7547a0b564b11800703893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4828e52b8b18470298c8d9c5e18b2e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "feb8b2e1d72945b4aa3d72720334c2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae2e68826f314d31b0fa5e9bafe5e695": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "914a052327d3449b9415540ba42e78f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c75a20b793b34ebe88a8a6d944399b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd7bf92f8c78438aaf04cc33999387fa",
              "IPY_MODEL_9d19280c6ea84f48beb638307e20c87d",
              "IPY_MODEL_b11f84e5511242b3af75589c3997a5f7"
            ],
            "layout": "IPY_MODEL_4b9c321b423443ff887c40c39f63296f"
          }
        },
        "dd7bf92f8c78438aaf04cc33999387fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52179b37560e4d859675f744d3965411",
            "placeholder": "​",
            "style": "IPY_MODEL_f51b1816386948e29d70dfc6c849c2a0",
            "value": "Fetching 15 files: 100%"
          }
        },
        "9d19280c6ea84f48beb638307e20c87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1a10f5713445739aeb6ae82bbcd0d1",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5b1b15e153e432a905d7a606cfea96f",
            "value": 15
          }
        },
        "b11f84e5511242b3af75589c3997a5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a79e7e9f78f4cf8bf9dbd8d6beacba7",
            "placeholder": "​",
            "style": "IPY_MODEL_547f2f00d05c44e58600e1472d0890b9",
            "value": " 15/15 [00:00&lt;00:00, 663.56it/s]"
          }
        },
        "4b9c321b423443ff887c40c39f63296f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52179b37560e4d859675f744d3965411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51b1816386948e29d70dfc6c849c2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f1a10f5713445739aeb6ae82bbcd0d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b1b15e153e432a905d7a606cfea96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a79e7e9f78f4cf8bf9dbd8d6beacba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547f2f00d05c44e58600e1472d0890b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18a88f1df4244bcf8e8134e7befe876d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b549718bfbfb4104beb92233a06780ca",
              "IPY_MODEL_d6ddd443828144feb7732ff35f8a90e7",
              "IPY_MODEL_0d0e09cc56174ccba976628ad336785f"
            ],
            "layout": "IPY_MODEL_075d92e97bfc41b48c1f168b4eaab51c"
          }
        },
        "b549718bfbfb4104beb92233a06780ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a13fb339e31b4ddf8f9e211a352f0c60",
            "placeholder": "​",
            "style": "IPY_MODEL_47edd10ec9c2476796801a3f114c80ac",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d6ddd443828144feb7732ff35f8a90e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78d8d07a19424c3d8a4c5750eef77051",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db11bd70888f44618b133ccffa01d670",
            "value": 3
          }
        },
        "0d0e09cc56174ccba976628ad336785f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d44ce2da61a4393a4f761ae9c97d5ee",
            "placeholder": "​",
            "style": "IPY_MODEL_5a03002065f841abb6947646c4f3aef5",
            "value": " 3/3 [01:10&lt;00:00, 23.14s/it]"
          }
        },
        "075d92e97bfc41b48c1f168b4eaab51c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13fb339e31b4ddf8f9e211a352f0c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47edd10ec9c2476796801a3f114c80ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78d8d07a19424c3d8a4c5750eef77051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db11bd70888f44618b133ccffa01d670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d44ce2da61a4393a4f761ae9c97d5ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a03002065f841abb6947646c4f3aef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Iu3BaBeyVn-",
        "outputId": "a30e6755-5612-4d79-b0d8-f71495670f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)\n",
            "  Downloading langchain_core-0.2.10-py3-none-any.whl (332 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.82-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.4/127.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.15.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-core-0.2.10 langchain-text-splitters-0.2.2 langsmith-0.1.82 orjson-3.10.5\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install langchain huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(\"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\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpDjMa0Zy2_I",
        "outputId": "b6a54810-c705-426f-b8d9-2bb7e0d5a9e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from huggingface_hub import snapshot_download\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to download the model\n",
        "mistral_models_path = Path.home().joinpath('mistral_models', '7B-Instruct-v0.3')\n",
        "mistral_models_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download the model with all necessary files\n",
        "snapshot_download(repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "                  local_dir=mistral_models_path,\n",
        "                  use_auth_token=True)  # Remove this line if you don't need authentication\n",
        "\n",
        "# Verify the downloaded files\n",
        "expected_files = [\"params.json\", \"consolidated.safetensors\", \"tokenizer.model.v3\", \"config.json\"]\n",
        "for file_name in expected_files:\n",
        "    file_path = mistral_models_path.joinpath(file_name)\n",
        "    if not file_path.exists():\n",
        "        raise FileNotFoundError(f\"Missing {file_name} in {mistral_models_path}\")\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(mistral_models_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    mistral_models_path,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    use_cache=True,\n",
        ")\n",
        "\n",
        "# Define Google Drive path\n",
        "drive_path = Path(\"/content/drive/My Drive/mistral_models/7B-Instruct-v0.3\")\n",
        "drive_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy model files to Google Drive\n",
        "for file_name in expected_files:\n",
        "    src_file_path = mistral_models_path.joinpath(file_name)\n",
        "    dest_file_path = drive_path.joinpath(file_name)\n",
        "    shutil.copy(src_file_path, dest_file_path)\n",
        "\n",
        "print(\"Model files have been successfully copied to Google Drive.\")\n",
        "\n",
        "# Test the pipeline\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "text = generator(\"Once upon a time, in a land far, far away, \", max_length=50)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "82cbbf0fcfaf46e0bca93455b8acb8db",
            "6ba668b67e7f46d684138c617aa6b5de",
            "c66c9508e53e48ef9592d8dfa20f1cd2",
            "57e51658cbf34ec1957af0eed79c71b6",
            "87794392f0b64768a313090ee0353e5a",
            "7c15711c76414fca95a64cae87f38b24",
            "a43dcdd40c7547a0b564b11800703893",
            "4828e52b8b18470298c8d9c5e18b2e95",
            "feb8b2e1d72945b4aa3d72720334c2ae",
            "ae2e68826f314d31b0fa5e9bafe5e695",
            "914a052327d3449b9415540ba42e78f9",
            "c75a20b793b34ebe88a8a6d944399b07",
            "dd7bf92f8c78438aaf04cc33999387fa",
            "9d19280c6ea84f48beb638307e20c87d",
            "b11f84e5511242b3af75589c3997a5f7",
            "4b9c321b423443ff887c40c39f63296f",
            "52179b37560e4d859675f744d3965411",
            "f51b1816386948e29d70dfc6c849c2a0",
            "8f1a10f5713445739aeb6ae82bbcd0d1",
            "c5b1b15e153e432a905d7a606cfea96f",
            "5a79e7e9f78f4cf8bf9dbd8d6beacba7",
            "547f2f00d05c44e58600e1472d0890b9",
            "18a88f1df4244bcf8e8134e7befe876d",
            "b549718bfbfb4104beb92233a06780ca",
            "d6ddd443828144feb7732ff35f8a90e7",
            "0d0e09cc56174ccba976628ad336785f",
            "075d92e97bfc41b48c1f168b4eaab51c",
            "a13fb339e31b4ddf8f9e211a352f0c60",
            "47edd10ec9c2476796801a3f114c80ac",
            "78d8d07a19424c3d8a4c5750eef77051",
            "db11bd70888f44618b133ccffa01d670",
            "1d44ce2da61a4393a4f761ae9c97d5ee",
            "5a03002065f841abb6947646c4f3aef5"
          ]
        },
        "id": "SV139gik0N99",
        "outputId": "2956a185-50dc-4d55-ce5b-1db47eaae67e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82cbbf0fcfaf46e0bca93455b8acb8db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c75a20b793b34ebe88a8a6d944399b07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18a88f1df4244bcf8e8134e7befe876d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model files have been successfully copied to Google Drive.\n",
            "[{'generated_text': 'Once upon a time, in a land far, far away, 100 years ago, there was a young girl named Mina. She lived in a small village nestled in the mountains. Mina was a curious girl, always asking'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear the Hugging Face cache\n",
        "!rm -rf ~/.cache/huggingface\n",
        "\n",
        "# Clear the PyTorch cache (optional)\n",
        "!rm -rf ~/.cache/torch\n",
        "\n",
        "# Check disk space usage\n",
        "!df -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMSOM84M0SbW",
        "outputId": "101b5b9e-1452-4530-d1c4-80a3916be308"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          79G   71G  7.5G  91% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G  4.0K  5.7G   1% /dev/shm\n",
            "/dev/root       2.0G  1.2G  820M  59% /usr/sbin/docker-init\n",
            "/dev/sda1       119G  109G   11G  91% /opt/bin/.nvidia\n",
            "tmpfs           6.4G  644K  6.4G   1% /var/colab\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "drive            15G  8.0G  7.1G  54% /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required packages\n",
        "!pip install langchain langchain-community\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from huggingface_hub import snapshot_download\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "\n",
        "# Set up the text generation pipeline\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=5000,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.15,\n",
        ")\n",
        "\n",
        "# Use the pipeline with LangChain\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0.1})\n",
        "\n",
        "# Define the prompt template for extracting total work experience\n",
        "work_experience_prompt_tpl = \"\"\"\n",
        "From the Resume text below, calculate the total work experience of the candidate. The result should be in years and months.\n",
        "Question: Calculate the total work experience for the text below -\n",
        "\n",
        "{text}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Create the chain for work experience extraction\n",
        "work_experience_prompt_template = PromptTemplate(template=work_experience_prompt_tpl, input_variables=['text'])\n",
        "work_experience_chain = LLMChain(llm=llm, prompt=work_experience_prompt_template)\n",
        "\n",
        "# Example resume text\n",
        "resume_text = \"\"\"\n",
        "Developer Developer Developer - TATA CONSULTANTCY SERVICE Batavia, OH Relevant course work: Database Systems, Database Administration, Database Security & Auditing, Computer Security, Computer Networks, Programming & Software Development, IT, Information Security Concept & Admin, IT System Acquisition & Integration, Advanced Web Development, and Ethical Hacking: Network Security & Pen Testing. Work Experience Developer TATA CONSULTANTCY SERVICE June 2016 to Present MRM (Government of ME, RI, MS) Developer: Working with various technologies such as Java, JSP, JSF, DB2(SQL), LDAP, BIRT report, Jazz version control, Squirrel SQL client, Hibernate, CSS, Linux, and Windows. Work as part of a team that provide support to enterprise applications. Perform miscellaneous support activities as requested by Management. Perform in-depth research and identify sources of production issues. SPLUNK Developer: Supporting the Splunk Operational environment for Business Solutions Unit aiming to support overall business infrastructure. Developing Splunk Queries to generate the report, monitoring, and analyzing machine generated big data for server that has been using for onsite and offshore team. Working with Splunk' premium apps such as ITSI, creating services, KPI, and glass tables. Developing app with custom dashboard with front-end ability and advanced XML to serve Business Solution unit' needs. Had in-house app presented at Splunk's .Conf Conference (2016). Help planning, prioritizing and executing development activities. Developer (front end) intern TOMORROW PICTURES INC - Atlanta, GA April 2015 to January 2016: Assist web development team with multiple front end web technologies and involved in web technologies such as Node.js, express, json, gulp.js, jade, sass, html5, css3, bootstrap, WordPress. Testing (manually), version control (GitHub), mock up design and ideas. Education: MASTER OF SCIENCE IN INFORMATION TECHNOLOGY in INFORMATION TECHNOLOGY KENNESAW STATE UNIVERSITY - Kennesaw, GA August 2012 to May 2015. MASTER OF BUSINESS ADMINISTRATION in INTERNATIONAL BUSINESS AMERICAN INTER CONTINENTAL UNIVERSITY ATLANTA November 2003 to December 2005. BACHELOR OF ARTS in PUBLIC RELATIONS THE UNIVERSITY OF THAI CHAMBER OF COMMERCE - BANGKOK, TH June 1997 to May 2001. Skills: Db2 (2 years), front end (2 years), Java (2 years), Linux (2 years), Splunk (2 years), SQL (3 years). Certifications/Licenses\n",
        "\"\"\"\n",
        "\n",
        "# Run the chain on the resume text\n",
        "work_experience_result = work_experience_chain.run({\"text\": resume_text})\n",
        "\n",
        "# Print the result\n",
        "print(\"Total Work Experience:\", work_experience_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7MGCkLY36pl",
        "outputId": "3ffb9d4b-8047-442c-d225-68ae08550127"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.82)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.6 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Work Experience: \n",
            "From the Resume text below, calculate the total work experience of the candidate. The result should be in years and months.\n",
            "Question: Calculate the total work experience for the text below -\n",
            "\n",
            "\n",
            "Developer Developer Developer - TATA CONSULTANTCY SERVICE Batavia, OH Relevant course work: Database Systems, Database Administration, Database Security & Auditing, Computer Security, Computer Networks, Programming & Software Development, IT, Information Security Concept & Admin, IT System Acquisition & Integration, Advanced Web Development, and Ethical Hacking: Network Security & Pen Testing. Work Experience Developer TATA CONSULTANTCY SERVICE June 2016 to Present MRM (Government of ME, RI, MS) Developer: Working with various technologies such as Java, JSP, JSF, DB2(SQL), LDAP, BIRT report, Jazz version control, Squirrel SQL client, Hibernate, CSS, Linux, and Windows. Work as part of a team that provide support to enterprise applications. Perform miscellaneous support activities as requested by Management. Perform in-depth research and identify sources of production issues. SPLUNK Developer: Supporting the Splunk Operational environment for Business Solutions Unit aiming to support overall business infrastructure. Developing Splunk Queries to generate the report, monitoring, and analyzing machine generated big data for server that has been using for onsite and offshore team. Working with Splunk' premium apps such as ITSI, creating services, KPI, and glass tables. Developing app with custom dashboard with front-end ability and advanced XML to serve Business Solution unit' needs. Had in-house app presented at Splunk's .Conf Conference (2016). Help planning, prioritizing and executing development activities. Developer (front end) intern TOMORROW PICTURES INC - Atlanta, GA April 2015 to January 2016: Assist web development team with multiple front end web technologies and involved in web technologies such as Node.js, express, json, gulp.js, jade, sass, html5, css3, bootstrap, WordPress. Testing (manually), version control (GitHub), mock up design and ideas. Education: MASTER OF SCIENCE IN INFORMATION TECHNOLOGY in INFORMATION TECHNOLOGY KENNESAW STATE UNIVERSITY - Kennesaw, GA August 2012 to May 2015. MASTER OF BUSINESS ADMINISTRATION in INTERNATIONAL BUSINESS AMERICAN INTER CONTINENTAL UNIVERSITY ATLANTA November 2003 to December 2005. BACHELOR OF ARTS in PUBLIC RELATIONS THE UNIVERSITY OF THAI CHAMBER OF COMMERCE - BANGKOK, TH June 1997 to May 2001. Skills: Db2 (2 years), front end (2 years), Java (2 years), Linux (2 years), Splunk (2 years), SQL (3 years). Certifications/Licenses\n",
            "\n",
            "\n",
            "Answer:\n",
            "The total work experience is approximately 4 years and 11 months. This calculation includes the current position as a developer at Tata Consultancy Services from June 2016 to the present day, and the previous position as a developer intern at Tomorrow Pictures Inc from April 2015 to January 2016.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the prompt template for work experience entity extraction\n",
        "work_experience_prompt_tpl = \"\"\"\n",
        "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
        "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
        "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
        "    Entity Definition:\n",
        "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
        "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
        "3. Do NOT create duplicate entities or properties\n",
        "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
        "5. DO NOT MISS out any Work Experience related entity\n",
        "6. NEVER Impute missing values\n",
        "Output JSON (Strict):\n",
        "{{\"entities\": [{{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}}]}}\n",
        "\n",
        "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
        "\n",
        "{text}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Create the chain for work experience extraction\n",
        "work_experience_prompt_template = PromptTemplate(template=work_experience_prompt_tpl, input_variables=['text'])\n",
        "work_experience_chain = LLMChain(llm=llm, prompt=work_experience_prompt_template)"
      ],
      "metadata": {
        "id": "oFbhVot88qo2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load your custom dataset\n",
        "file_path = '/content/extracted_resumes.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract the text column\n",
        "resume_texts = df.iloc[:, 1].tolist()\n",
        "\n",
        "# Function to extract work experience entities from resume text\n",
        "def extract_work_experience(resume_text):\n",
        "    try:\n",
        "        result = work_experience_chain.invoke({\"text\": resume_text})\n",
        "        raw_output = result['text']\n",
        "        print(f\"Raw output:\\n{raw_output}\\n\")  # Print raw output for debugging\n",
        "        output = json.loads(raw_output)\n",
        "        return output.get('entities', [])\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON decoding error: {e}\")\n",
        "        print(f\"Raw output:\\n{raw_output}\\n\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing resume: {e}\")\n",
        "        return []\n",
        "\n",
        "# Run the extraction on all resumes\n",
        "all_entities = []\n",
        "for text in resume_texts:\n",
        "    entities = extract_work_experience(text)\n",
        "    all_entities.append({\"entities\": entities})\n",
        "\n",
        "# Save the extracted entities to a JSONL file\n",
        "output_file_path = '/content/extracted_work_experience.jsonl'\n",
        "with open(output_file_path, 'w') as f:\n",
        "    for entry in all_entities:\n",
        "        json.dump(entry, f)\n",
        "        f.write('\\n')\n",
        "\n",
        "print(f\"Work experience entities have been saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ChFoYNlUET2Z",
        "outputId": "758ddfbe-f313-4a91-c4f4-a0fb6359ee46"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "Ajay A \n",
            "JUNIOR-HR \n",
            "ajayasok04@gmail.com                           \n",
            " \n",
            "                             +91-8838543432 \n",
            "                                                                                        \n",
            "  PROFESSIONAL SUMMARY \n",
            " \n",
            "An altruistic and self-motivated person who wish to pursue a career in HR with a progressive \n",
            "organization that provides a scope to combine multidisciplinary skills of human resources and \n",
            "management in a dynamic environment. \n",
            " \n",
            "   PROFESSIONAL EXPERIENCE  \n",
            " \n",
            "JUNIOR-HR ASSOCIATE                                                                                Oct 2021- March 2022 \n",
            "ACHERON SOFTWARE CONSULTANCY PVT LTD                                      (Hyderabad)    \n",
            " \n",
            "     Roles and Responsibilities: \n",
            "• \n",
            "Screen candidates for open job requirements. \n",
            "• \n",
            "Conduct phone Interviews and in person interviews. \n",
            "• \n",
            "Follow up candidates for the interview and offers. \n",
            "• \n",
            "Supporting Talent acquisition team for sourcing profiles from various job portals \n",
            "(Naukri,Linkedin jobs etc). \n",
            "• \n",
            "Managing Calendar and roll out Google forms for the performance and training feedbacks. \n",
            "• \n",
            "Organize internal events as a part of company culture bonding employees. \n",
            "• \n",
            "Recommend new approaches, policies and procedure to improve the effectiveness. \n",
            "• \n",
            "Implemented new HRMS Software (KEKA) for free flow of HR- operations. \n",
            "• \n",
            "Maintaining Employee database, attendance & leave management through the HR portal. \n",
            "• \n",
            "Organize ergonomic session for employees to maintain the working    posture and keeping the \n",
            "environment healthy. \n",
            "• \n",
            "Empathy program for the better cultural bonding and growth of the organization. \n",
            "• \n",
            "Scheduling interviews and rolling out offers, Salary negotiations, on- boarding and orientation. \n",
            "• \n",
            "Managing resources by allocating to project managers. \n",
            "• \n",
            "Sourcing Training programs for employees. \n",
            "• \n",
            "Employee retention. \n",
            "• \n",
            "Organizing Company annual kick-off event by sourcing the venue and negotiating the financial \n",
            "standards. \n",
            "• \n",
            "Supporting Immigration and Visa process to the CEO and Managers for Business trips. \n",
            "• \n",
            "Supporting Admin in maintaining the People availability form and employee directory in MS \n",
            "excel. \n",
            "• \n",
            "Organize Outdoor activities for a better bonding between the peers. \n",
            " \n",
            " HUMAN RESOURCE BUSINESS PARTNER                                            March 2021 – Sept 2021 \n",
            " KRISHNAA ENTERPRISES                                                                                     (Coimbatore) \n",
            "     Roles and Responsibilities: \n",
            "• \n",
            "Improving and monitoring employee productivity. \n",
            "• \n",
            "Structuring compensation and benefit packages. \n",
            "• \n",
            "Managing staff wellness initiatives. \n",
            "• \n",
            "Improving relations between staff and employers. \n",
            "• \n",
            "Building relationships and finding resources for the labor requirements. \n",
            "• \n",
            "Strategically retaining customers by being flexible and negotiating. \n",
            "• \n",
            "Convincing and consulting customer grievances. \n",
            "• \n",
            "Assisted with administration and operations for a fast-paced retail business. \n",
            " \n",
            "         BUSINESS DEVELOPMENT ASSOCIATE                                       June 2017 – Feb 2021 \n",
            "         KRISHNAA ENTERPRISES                                                                        (Coimbatore) \n",
            "        Roles and Responsibilities: \n",
            " \n",
            "• \n",
            "Quality control and assurance. \n",
            "• \n",
            "Negotiating with labors in production of finished goods. \n",
            "• \n",
            "Organized the transshipment of materials from end to end. \n",
            "• \n",
            "Identify new business opportunities. \n",
            "• \n",
            "Cultivating strong relationships with new clients, while maintaining existing client relationships. \n",
            "• \n",
            "Ability to manage multiple projects concurrently and meet deadlines. \n",
            "• \n",
            "Demonstrate strong interpersonal skills with the ability to engage labors effectively. \n",
            "• \n",
            "Material management in various grade metals like stainless steel (SS304, 316,410etc.) \n",
            " \n",
            "   KEY COMPETENCIES \n",
            "• \n",
            "Microsoft Word, Excel, Power point. \n",
            "• \n",
            "Google Calendar, Sheets, Slides. \n",
            "• \n",
            "KEKA HRMS Software. \n",
            "• \n",
            "Job Portals. \n",
            "TRAINING & CERTIFICATONS \n",
            "• \n",
            "MS- Office. \n",
            "• \n",
            "Talent Acquisition & Hiring (Udemy). \n",
            "• \n",
            "SAP-HR Beginners (Udemy). \n",
            "EDUCATION \n",
            "MBA - CMS INSTITUTE OF MANAGEMENT STUDIES                                           April-2017        \n",
            "      HR & Logistics - 69%.                                                                                                      Coimbatore \n",
            "B.A - CMS COLLEGE OF SCIENCE & COMMERCE                                                   April-2015 \n",
            "     English Literature - 66%                                                                                                   Coimbatore \n",
            "   PERSONAL INFORMATION \n",
            "Marital Status: Single \n",
            "Date of Birth: 08-July-1995 \n",
            "   LANGUAGE PROFICIENCY \n",
            "English| Hindi| Tamil| Malayalam \n",
            "HOBBIES AND INTEREST \n",
            "• \n",
            "Being a football player since childhood, I love sports. I always want myself to be fit and sporty. \n",
            "• \n",
            "Love Singing. \n",
            "• \n",
            "Love to draw and paint. \n",
            " \n",
            "DECLARATION \n",
            "I hereby declare that the contents of my resume are accurate to the best of my knowledge and verify their \n",
            "authenticity. \n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"JUNIOR-HR ASSOCIATE\",\"company\":\"ACHERON SOFTWARE CONSULTANCY PVT LTD\",\"description\":\"Worked as Junior-HR Associate at ACHERON SOFTWARE CONSULTANCY PVT LTD from October 2021 to March 2022. Responsibilities included screening candidates, conducting interviews, managing calendar, organizing internal events, implementing new HRMS software, maintaining employee database, organizing ergonomic sessions, empathy program, scheduling interviews, managing resources, sourcing training programs, employee retention, organizing company annual kick-off event, supporting immigration and visa process, supporting admin in maintaining people availability form and employee directory in MS excel, organizing outdoor activities.\",\"startDate\":\"October 2021\",\"endDate\":\"March 2022\"},{\"label\":\"Work Experience\",\"id\":\"experience2\",\"role\":\"HUMAN RESOURCE BUSINESS PARTNER\",\"company\":\"KRISHNAA ENTERPRISES\",\"description\":\"Worked as Human Resource Business Partner at KRISHNAA ENTERPRISES from March 2021 to September 2021. Responsibilities included improving and monitoring employee productivity, structuring compensation and benefit packages, managing staff wellness initiatives, improving relations between staff and employers, building relationships and finding resources for the labor requirements, strategically retaining customers, convincing and consulting customer grievances, assisting with administration and operations for a fast-paced retail business.\",\"startDate\":\"March 2021\",\"endDate\":\"September 2021\"},{\"label\":\"Work Experience\",\"id\":\"experience3\",\"role\":\"BUSINESS DEVELOPMENT ASSOCIATE\",\"company\":\"KRISHNAA ENTERPRISES\",\"description\":\"Worked as Business Development Associate at KRISHNAA ENTERPRISES from June 2017 to February 2021. Responsibilities included quality control and assurance, negotiating with labors in production of finished goods, organizing the transshipment of materials from end to end, identifying new business opportunities, cultivating strong relationships with new clients, while maintaining existing client relationships, ability to manage multiple projects concurrently and meet deadlines, demonstrating strong interpersonal skills with the ability to engage labors effectively, material management in various grade metals like stainless steel (SS304, 316,410etc.).\",\"startDate\":\"June 2017\",\"endDate\":\"February 2021\"}]}\n",
            "\n",
            "JSON decoding error: Expecting value: line 2 column 1 (char 1)\n",
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "Ajay A \n",
            "JUNIOR-HR \n",
            "ajayasok04@gmail.com                           \n",
            " \n",
            "                             +91-8838543432 \n",
            "                                                                                        \n",
            "  PROFESSIONAL SUMMARY \n",
            " \n",
            "An altruistic and self-motivated person who wish to pursue a career in HR with a progressive \n",
            "organization that provides a scope to combine multidisciplinary skills of human resources and \n",
            "management in a dynamic environment. \n",
            " \n",
            "   PROFESSIONAL EXPERIENCE  \n",
            " \n",
            "JUNIOR-HR ASSOCIATE                                                                                Oct 2021- March 2022 \n",
            "ACHERON SOFTWARE CONSULTANCY PVT LTD                                      (Hyderabad)    \n",
            " \n",
            "     Roles and Responsibilities: \n",
            "• \n",
            "Screen candidates for open job requirements. \n",
            "• \n",
            "Conduct phone Interviews and in person interviews. \n",
            "• \n",
            "Follow up candidates for the interview and offers. \n",
            "• \n",
            "Supporting Talent acquisition team for sourcing profiles from various job portals \n",
            "(Naukri,Linkedin jobs etc). \n",
            "• \n",
            "Managing Calendar and roll out Google forms for the performance and training feedbacks. \n",
            "• \n",
            "Organize internal events as a part of company culture bonding employees. \n",
            "• \n",
            "Recommend new approaches, policies and procedure to improve the effectiveness. \n",
            "• \n",
            "Implemented new HRMS Software (KEKA) for free flow of HR- operations. \n",
            "• \n",
            "Maintaining Employee database, attendance & leave management through the HR portal. \n",
            "• \n",
            "Organize ergonomic session for employees to maintain the working    posture and keeping the \n",
            "environment healthy. \n",
            "• \n",
            "Empathy program for the better cultural bonding and growth of the organization. \n",
            "• \n",
            "Scheduling interviews and rolling out offers, Salary negotiations, on- boarding and orientation. \n",
            "• \n",
            "Managing resources by allocating to project managers. \n",
            "• \n",
            "Sourcing Training programs for employees. \n",
            "• \n",
            "Employee retention. \n",
            "• \n",
            "Organizing Company annual kick-off event by sourcing the venue and negotiating the financial \n",
            "standards. \n",
            "• \n",
            "Supporting Immigration and Visa process to the CEO and Managers for Business trips. \n",
            "• \n",
            "Supporting Admin in maintaining the People availability form and employee directory in MS \n",
            "excel. \n",
            "• \n",
            "Organize Outdoor activities for a better bonding between the peers. \n",
            " \n",
            " HUMAN RESOURCE BUSINESS PARTNER                                            March 2021 – Sept 2021 \n",
            " KRISHNAA ENTERPRISES                                                                                     (Coimbatore) \n",
            "     Roles and Responsibilities: \n",
            "• \n",
            "Improving and monitoring employee productivity. \n",
            "• \n",
            "Structuring compensation and benefit packages. \n",
            "• \n",
            "Managing staff wellness initiatives. \n",
            "• \n",
            "Improving relations between staff and employers. \n",
            "• \n",
            "Building relationships and finding resources for the labor requirements. \n",
            "• \n",
            "Strategically retaining customers by being flexible and negotiating. \n",
            "• \n",
            "Convincing and consulting customer grievances. \n",
            "• \n",
            "Assisted with administration and operations for a fast-paced retail business. \n",
            " \n",
            "         BUSINESS DEVELOPMENT ASSOCIATE                                       June 2017 – Feb 2021 \n",
            "         KRISHNAA ENTERPRISES                                                                        (Coimbatore) \n",
            "        Roles and Responsibilities: \n",
            " \n",
            "• \n",
            "Quality control and assurance. \n",
            "• \n",
            "Negotiating with labors in production of finished goods. \n",
            "• \n",
            "Organized the transshipment of materials from end to end. \n",
            "• \n",
            "Identify new business opportunities. \n",
            "• \n",
            "Cultivating strong relationships with new clients, while maintaining existing client relationships. \n",
            "• \n",
            "Ability to manage multiple projects concurrently and meet deadlines. \n",
            "• \n",
            "Demonstrate strong interpersonal skills with the ability to engage labors effectively. \n",
            "• \n",
            "Material management in various grade metals like stainless steel (SS304, 316,410etc.) \n",
            " \n",
            "   KEY COMPETENCIES \n",
            "• \n",
            "Microsoft Word, Excel, Power point. \n",
            "• \n",
            "Google Calendar, Sheets, Slides. \n",
            "• \n",
            "KEKA HRMS Software. \n",
            "• \n",
            "Job Portals. \n",
            "TRAINING & CERTIFICATONS \n",
            "• \n",
            "MS- Office. \n",
            "• \n",
            "Talent Acquisition & Hiring (Udemy). \n",
            "• \n",
            "SAP-HR Beginners (Udemy). \n",
            "EDUCATION \n",
            "MBA - CMS INSTITUTE OF MANAGEMENT STUDIES                                           April-2017        \n",
            "      HR & Logistics - 69%.                                                                                                      Coimbatore \n",
            "B.A - CMS COLLEGE OF SCIENCE & COMMERCE                                                   April-2015 \n",
            "     English Literature - 66%                                                                                                   Coimbatore \n",
            "   PERSONAL INFORMATION \n",
            "Marital Status: Single \n",
            "Date of Birth: 08-July-1995 \n",
            "   LANGUAGE PROFICIENCY \n",
            "English| Hindi| Tamil| Malayalam \n",
            "HOBBIES AND INTEREST \n",
            "• \n",
            "Being a football player since childhood, I love sports. I always want myself to be fit and sporty. \n",
            "• \n",
            "Love Singing. \n",
            "• \n",
            "Love to draw and paint. \n",
            " \n",
            "DECLARATION \n",
            "I hereby declare that the contents of my resume are accurate to the best of my knowledge and verify their \n",
            "authenticity. \n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"JUNIOR-HR ASSOCIATE\",\"company\":\"ACHERON SOFTWARE CONSULTANCY PVT LTD\",\"description\":\"Worked as Junior-HR Associate at ACHERON SOFTWARE CONSULTANCY PVT LTD from October 2021 to March 2022. Responsibilities included screening candidates, conducting interviews, managing calendar, organizing internal events, implementing new HRMS software, maintaining employee database, organizing ergonomic sessions, empathy program, scheduling interviews, managing resources, sourcing training programs, employee retention, organizing company annual kick-off event, supporting immigration and visa process, supporting admin in maintaining people availability form and employee directory in MS excel, organizing outdoor activities.\",\"startDate\":\"October 2021\",\"endDate\":\"March 2022\"},{\"label\":\"Work Experience\",\"id\":\"experience2\",\"role\":\"HUMAN RESOURCE BUSINESS PARTNER\",\"company\":\"KRISHNAA ENTERPRISES\",\"description\":\"Worked as Human Resource Business Partner at KRISHNAA ENTERPRISES from March 2021 to September 2021. Responsibilities included improving and monitoring employee productivity, structuring compensation and benefit packages, managing staff wellness initiatives, improving relations between staff and employers, building relationships and finding resources for the labor requirements, strategically retaining customers, convincing and consulting customer grievances, assisting with administration and operations for a fast-paced retail business.\",\"startDate\":\"March 2021\",\"endDate\":\"September 2021\"},{\"label\":\"Work Experience\",\"id\":\"experience3\",\"role\":\"BUSINESS DEVELOPMENT ASSOCIATE\",\"company\":\"KRISHNAA ENTERPRISES\",\"description\":\"Worked as Business Development Associate at KRISHNAA ENTERPRISES from June 2017 to February 2021. Responsibilities included quality control and assurance, negotiating with labors in production of finished goods, organizing the transshipment of materials from end to end, identifying new business opportunities, cultivating strong relationships with new clients, while maintaining existing client relationships, ability to manage multiple projects concurrently and meet deadlines, demonstrating strong interpersonal skills with the ability to engage labors effectively, material management in various grade metals like stainless steel (SS304, 316,410etc.).\",\"startDate\":\"June 2017\",\"endDate\":\"February 2021\"}]}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "Abid Ibrahim \n",
            "Developer/Blockchain Enthusiast \n",
            "abidibrahim3304@gmail.com \n",
            "+91 7012847450 \n",
            "Kozhikode, India \n",
            "linkedin.com/in/abid-ibrahim-229886191 \n",
            "github.com/Abid-Ibrahim \n",
            "EDUCATION \n",
            "Bachelor’s Degree in Information\n",
            "Technology \n",
            "Cochin University of Science And\n",
            "Technology \n",
            "08/2019 - Present,  \n",
            "Primary Education \n",
            "St.Mary's English Medium School \n",
            "2004 - 2016,  \n",
            "ICSE Board -90.6% \n",
            "Higher Secondary Education \n",
            "Silver Hills Public School \n",
            "2016 - 2018,  \n",
            "CBSE Board - 82.8 \n",
            "WORK EXPERIENCE \n",
            "Intern/Trainee \n",
            "Homomorphic Solutions \n",
            "02/2022 - Present,  \n",
            "SKILLS \n",
            "Python \n",
            "React.js \n",
            "C++ \n",
            "Communication Skills \n",
            "Typescript \n",
            "SQL \n",
            "Git \n",
            "Teamwork \n",
            "PERSONAL PROJECTS \n",
            "Chiliagon DAO Website \n",
            "https://chiliagondao.on.ﬂeek.co/ \n",
            "College Management System \n",
            "https://github.com/Abid-Ibrahim/college-management-system \n",
            "Quit Smoke App \n",
            "https://github.com/Abid-Ibrahim/Quit-Smoke-App \n",
            "CERTIFICATES \n",
            "Python Certiﬁcate (03/2022 - Present) \n",
            "https://www.kaggle.com/learn/certiﬁcation/abid19/python \n",
            "30 Days of Google Cloud 2021 \n",
            "https://drive.google.com/ﬁle/d/1_WP2X4C39DSRLlDzp_Y7mi7T3ci6Yea\n",
            "m/view?usp=sharing \n",
            "LANGUAGES \n",
            "English \n",
            "Native or Bilingual Proﬁciency \n",
            "Malayalam \n",
            "Native or Bilingual Proﬁciency \n",
            "Hindi \n",
            "Native or Bilingual Proﬁciency \n",
            "INTERESTS \n",
            "Coding \n",
            "Football \n",
            "Crypto \n",
            "Reading \n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Intern/Trainee\",\"company\":\"Homomorphic Solutions\",\"description\":\"Not provided.\",\"startDate\":\"02/2022\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "JSON decoding error: Expecting value: line 2 column 1 (char 1)\n",
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "Abid Ibrahim \n",
            "Developer/Blockchain Enthusiast \n",
            "abidibrahim3304@gmail.com \n",
            "+91 7012847450 \n",
            "Kozhikode, India \n",
            "linkedin.com/in/abid-ibrahim-229886191 \n",
            "github.com/Abid-Ibrahim \n",
            "EDUCATION \n",
            "Bachelor’s Degree in Information\n",
            "Technology \n",
            "Cochin University of Science And\n",
            "Technology \n",
            "08/2019 - Present,  \n",
            "Primary Education \n",
            "St.Mary's English Medium School \n",
            "2004 - 2016,  \n",
            "ICSE Board -90.6% \n",
            "Higher Secondary Education \n",
            "Silver Hills Public School \n",
            "2016 - 2018,  \n",
            "CBSE Board - 82.8 \n",
            "WORK EXPERIENCE \n",
            "Intern/Trainee \n",
            "Homomorphic Solutions \n",
            "02/2022 - Present,  \n",
            "SKILLS \n",
            "Python \n",
            "React.js \n",
            "C++ \n",
            "Communication Skills \n",
            "Typescript \n",
            "SQL \n",
            "Git \n",
            "Teamwork \n",
            "PERSONAL PROJECTS \n",
            "Chiliagon DAO Website \n",
            "https://chiliagondao.on.ﬂeek.co/ \n",
            "College Management System \n",
            "https://github.com/Abid-Ibrahim/college-management-system \n",
            "Quit Smoke App \n",
            "https://github.com/Abid-Ibrahim/Quit-Smoke-App \n",
            "CERTIFICATES \n",
            "Python Certiﬁcate (03/2022 - Present) \n",
            "https://www.kaggle.com/learn/certiﬁcation/abid19/python \n",
            "30 Days of Google Cloud 2021 \n",
            "https://drive.google.com/ﬁle/d/1_WP2X4C39DSRLlDzp_Y7mi7T3ci6Yea\n",
            "m/view?usp=sharing \n",
            "LANGUAGES \n",
            "English \n",
            "Native or Bilingual Proﬁciency \n",
            "Malayalam \n",
            "Native or Bilingual Proﬁciency \n",
            "Hindi \n",
            "Native or Bilingual Proﬁciency \n",
            "INTERESTS \n",
            "Coding \n",
            "Football \n",
            "Crypto \n",
            "Reading \n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Intern/Trainee\",\"company\":\"Homomorphic Solutions\",\"description\":\"Not provided.\",\"startDate\":\"02/2022\",\"endDate\":\"Present\"}]}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "   ABIJITH K                        \n",
            "  \n",
            "Mobile: +91-9745493045  \n",
            "Email: abijithk539@gmail.com  \n",
            "OBJECTIVE  \n",
            "• \n",
            "Looking for a challenging career which demands the best of my professional ability in terms of \n",
            "technical and analytical skills, and helps me in broadening and enhancing my current skill and \n",
            "knowledge.  \n",
            "• \n",
            "To learn from the challenges in the industry and make myself capable to face new challenge.  \n",
            "EDUCATION  \n",
            "• \n",
            "Bachelor of Commerce in Computer Application  \n",
            "               University of Calicut  \n",
            "               2017-2020 \n",
            "• \n",
            "Plus Two \n",
            "Govt.Higher Secondary School \n",
            "2015 – 2017 \n",
            "• \n",
            "SSLC \n",
            "Govt.Higher Secondary School \n",
            "2004 – 2015 \n",
            " \n",
            "STRENGTH & ABILITIES  \n",
            "• \n",
            "Strong analytical and mathematical skills.  \n",
            "• \n",
            "Physically fit and mentally alert.  \n",
            "• \n",
            "Good communication, team player, hardworking and flexible.  \n",
            "    SOFTWARE SKILLS  \n",
            " \n",
            "• \n",
            "Python, Django, HTML, CSS, SQL \n",
            " \n",
            "    CERTIFICATION  \n",
            "  \n",
            "• \n",
            "Attended Online course on Python Django.  \n",
            "PROJECTS  \n",
            " \n",
            "• Login System in Django \n",
            "• Todo app using Django  \n",
            " \n",
            " \n",
            " \n",
            "PERSONAL DETAILS  \n",
            "  \n",
            " Name  \n",
            ": Abijith K   \n",
            " Date of birth              \n",
            "    : 16-06-1999  \n",
            "Father’s Name                                             : Hariharan K  \n",
            "Sex  \n",
            "    : Male  \n",
            "Nationality  \n",
            "                                          : Indian  \n",
            "Marital Status                                             : Single  \n",
            "Languages Known.                                     : English, Malayalam  \n",
            "Hobbies  \n",
            "                                          : Music, Driving, Travelling   \n",
            "Address  \n",
            "                                          : Kunnathadukkath (H)  \n",
            "    Payambra (PO)  \n",
            "          Kozhikode (Dist.)  \n",
            "        Kerala 673571  \n",
            "DECLARATION  \n",
            "I do hereby declare that the particulars furnished above are true and correct to the best of my knowledge \n",
            "and belief.  \n",
            "Yours sincerely,  \n",
            "                                                                                                                                             ABIJITH K  \n",
            "    \n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Not Mentioned\",\"company\":\"Not Mentioned\",\"description\":\"Not Mentioned\",\"startDate\":\"Not Mentioned\",\"endDate\":\"Not Mentioned\"}]}\n",
            "\n",
            "JSON decoding error: Expecting value: line 2 column 1 (char 1)\n",
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "   ABIJITH K                        \n",
            "  \n",
            "Mobile: +91-9745493045  \n",
            "Email: abijithk539@gmail.com  \n",
            "OBJECTIVE  \n",
            "• \n",
            "Looking for a challenging career which demands the best of my professional ability in terms of \n",
            "technical and analytical skills, and helps me in broadening and enhancing my current skill and \n",
            "knowledge.  \n",
            "• \n",
            "To learn from the challenges in the industry and make myself capable to face new challenge.  \n",
            "EDUCATION  \n",
            "• \n",
            "Bachelor of Commerce in Computer Application  \n",
            "               University of Calicut  \n",
            "               2017-2020 \n",
            "• \n",
            "Plus Two \n",
            "Govt.Higher Secondary School \n",
            "2015 – 2017 \n",
            "• \n",
            "SSLC \n",
            "Govt.Higher Secondary School \n",
            "2004 – 2015 \n",
            " \n",
            "STRENGTH & ABILITIES  \n",
            "• \n",
            "Strong analytical and mathematical skills.  \n",
            "• \n",
            "Physically fit and mentally alert.  \n",
            "• \n",
            "Good communication, team player, hardworking and flexible.  \n",
            "    SOFTWARE SKILLS  \n",
            " \n",
            "• \n",
            "Python, Django, HTML, CSS, SQL \n",
            " \n",
            "    CERTIFICATION  \n",
            "  \n",
            "• \n",
            "Attended Online course on Python Django.  \n",
            "PROJECTS  \n",
            " \n",
            "• Login System in Django \n",
            "• Todo app using Django  \n",
            " \n",
            " \n",
            " \n",
            "PERSONAL DETAILS  \n",
            "  \n",
            " Name  \n",
            ": Abijith K   \n",
            " Date of birth              \n",
            "    : 16-06-1999  \n",
            "Father’s Name                                             : Hariharan K  \n",
            "Sex  \n",
            "    : Male  \n",
            "Nationality  \n",
            "                                          : Indian  \n",
            "Marital Status                                             : Single  \n",
            "Languages Known.                                     : English, Malayalam  \n",
            "Hobbies  \n",
            "                                          : Music, Driving, Travelling   \n",
            "Address  \n",
            "                                          : Kunnathadukkath (H)  \n",
            "    Payambra (PO)  \n",
            "          Kozhikode (Dist.)  \n",
            "        Kerala 673571  \n",
            "DECLARATION  \n",
            "I do hereby declare that the particulars furnished above are true and correct to the best of my knowledge \n",
            "and belief.  \n",
            "Yours sincerely,  \n",
            "                                                                                                                                             ABIJITH K  \n",
            "    \n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Not Mentioned\",\"company\":\"Not Mentioned\",\"description\":\"Not Mentioned\",\"startDate\":\"Not Mentioned\",\"endDate\":\"Not Mentioned\"}]}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "C.ABINAYA, B.E \n",
            "DOT NET DEVELOPER \n",
            "(abinayachandran1997@gmail.com, 6369387648) \n",
            " \n",
            "Professional Summary: \n",
            " \n",
            "• 4 years of experience in Software Development Life Cycle (SDLC) involving Requirement Gathering, \n",
            "Analysis, Logical and Physical Architectural Modeling, Design, Development, Testing, Implementation, \n",
            "Deployment and Production Support. \n",
            "• Worked on agile methodology to meet timelines with quality deliverables. \n",
            "• Able to work as a team player as well as individually. Highly organized, dedicated with a positive attitude \n",
            "along with the strong analytical and trouble shooting skills. \n",
            "• Worked with business directly taking inputs for implementing new functionalities or modifying existing \n",
            "features as needed. \n",
            "• Experienced in working with dev, database admins, deployment team and managers for getting task \n",
            "done on timely fashion. \n",
            "• Adept at working on multiple projects simultaneously. \n",
            "• Good communication skills, team player. \n",
            " \n",
            "Education: \n",
            "• Bachelor of Engineering, Vins Christian College of Engineering, Tamil Nadu, India. Years: March 2013 – \n",
            "May 2017. \n",
            " \n",
            "Certification: \n",
            "• Certification in C# Software Development, CKS Solutions. \n",
            "• Certification in Asp.net Web Development, Shiva Technology Solutions. \n",
            " \n",
            "Technical Skills: \n",
            "• \n",
            "Backend                                              : \n",
            "DOT NET Core, Web API, C #, ADO.NET, LINQ, Entity Framework. \n",
            "• Markup Languages                      : \n",
            "HTML, JSON. \n",
            "• Styles                                             : \n",
            "CSS3. \n",
            "• Database                                       :  \n",
            "MSSQL Server. \n",
            "• \n",
            "Version Controls                               :          Github, Azure Dev Ops. \n",
            "• Development Tools                     : \n",
            "MS Visual Studio, SQL Server Management  Studio. \n",
            " \n",
            "Professional Experiences: \n",
            " \n",
            "Employer: CKS Solutions \n",
            "Position: Dot Net Developer \n",
            "                   Oct 2021 – Till Date \n",
            "Location: Nagercoil. \n",
            " \n",
            " \n",
            "Project: CareerIn \n",
            "Responsibilities: \n",
            "• Implemented Entity framework in .Net Core to develop API for CareerIn, which supports both mobile \n",
            "and web application. \n",
            "• Designed user interface for the application using ASP.Net MVVM Architecture and implemented \n",
            "business logic using C#.Net. \n",
            "• Experience with code-first ORMs. \n",
            " \n",
            "• Developed an entity framework model and Implemented LINQ for querying, sorting, filtering the \n",
            "complex objects. \n",
            "• Object Oriented Programming languages (OOPS) concepts has been used to implement Business logic \n",
            "layer. \n",
            "• Tools used for automation are REST API testing from Visual Studio 2019, SQL Server 2019 for backend \n",
            "data management, Postman for manual REST API testing, and Swagger UI for getting model view for \n",
            "APIs. \n",
            "• Experience with database backups, restores and recovery models. \n",
            "• Used Azure Dev Ops for source control. \n",
            " \n",
            "Environment: Visual Studio 2019, .NET Core, Entity Framework, LINQ, C#.NET, SQL, Azure Dev Ops. \n",
            " \n",
            "Project: Yamaha Customer Loyalty Administration  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Responsibilities: \n",
            "• Implemented Entity framework in .Net Core to develop API for Yamaha Customer Loyalty \n",
            "Administration, which supports both mobile and web application. \n",
            "• Had good collaboration with front-end developers in order to build the structure of the website. \n",
            "• Object Oriented Programming languages (OOPS) concepts has been used to implement Business logic \n",
            "layer. \n",
            "• Designed user interface for the application using ASP.Net MVVM Architecture and implemented \n",
            "business logic using C#.Net. \n",
            "• Experience with code-first ORMs. \n",
            "• Provided API/Web Services endpoint automation. \n",
            "• Tools used for automation are REST API testing from Visual Studio 2019, SQL Server 2019 for backend \n",
            "data management, Postman for manual REST API testing, and Swagger UI for getting model view for \n",
            "APIs. \n",
            "• Developed an entity framework model and Implemented LINQ for querying, sorting, filtering the \n",
            "complex objects. \n",
            "• Provided QA support by involving in technical discussions, providing a test plan, automating and \n",
            "executing the test cases. \n",
            "• Implemented security settings in IIS. \n",
            "• Used GIT for repository control and Azure Dev Ops for source control. \n",
            " \n",
            "Environment: Visual Studio 2019, .NET Core, ADO.NET, Entity Framework, LINQ, C#.NET, SQL, Azure Dev Ops. \n",
            " \n",
            "Project: WeTeams \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Responsibilities: \n",
            "• All the layers of the application developed using C# and .NET Core. \n",
            "• Business logic layer implemented by Object Oriented Programming Languages (OOPS) concepts. \n",
            "• Strong experience in programming with .NET Framework using C#, ADO.NET, Entity Framework, \n",
            "ASP.NET, Visual Studio 2019, SQL Server 2019. \n",
            "• Implemented LINQ Query operations like Grouping, Ordering and Filtering operations to access database \n",
            "for search of drivers and packages. \n",
            "• Using Entity framework with Automapper for mapping entities to Database objects. \n",
            "• Implemented security settings in IIS. \n",
            "• Designed user interface for the application using ASP.Net MVC and implemented business logic using \n",
            "C#.Net. \n",
            "• Using GIT for repository control and Azure Dev Ops for source control. \n",
            "• Implemented Cron job scheduler to run API automatically. \n",
            "• Involved in investigating the test failures and fixing the automation tests and filing any bugs if discovered. \n",
            "• JWT Token authorization for all API calls for security purpose. \n",
            " \n",
            "Environment: Visual Studio 2019, .NET Core, ADO.NET, C#.NET, SQL, GitHub. \n",
            "Employer: Shiva Technology Solutions \n",
            "Position: Software Developer \n",
            "               May 2018 – Sep 2021 \n",
            "Location: Nagercoil \n",
            " \n",
            " \n",
            "Project: AKIS  \n",
            " \n",
            " \n",
            "  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Responsibilities: \n",
            "• Designed and developed various abstract classes, interfaces, classes to construct the business logic using \n",
            "C# with OOPS implementation. \n",
            "• Involved in the technical group that implements organizational level framework changes. \n",
            "• Exposed to various stages of Software Development Life Cycle on Client/Server, Multi-tired and Web-\n",
            "based applications. \n",
            "• Implemented the business rules using the Stored procedures in SQL Server to improve the performance. \n",
            "• Used Asp.Net validation controls for Client-side validation of server controls. \n",
            "• Done Code review and provide feedback to dev and QA work within team. \n",
            "• Designed and Effectively Implemented the State Management to improve the performance of the \n",
            "application. \n",
            "• Developed and supported application systems in accordance with established standards and processes. \n",
            " \n",
            "Environment: Visual Studio 2013, Asp .Net, C#.NET, SQL SERVER, HTML, CSS, JavaScript. \n",
            " \n",
            "Project: Human Well Being System  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Responsibilities: \n",
            "• Effectively designed and Implemented the State Management to improve the performance of the \n",
            "application. \n",
            "• Used ASP.NET with C# while developing the web forms to meet the user requirements. \n",
            "• Involved in the technical group that implements organizational level framework changes. \n",
            "• Involved in the design of database, developed Packages and Stored Procedures using SQL. \n",
            "• Business logic layer has been implemented by Object Oriented Programming (OOPS) Concepts. \n",
            "• Implemented reporting application for information retrieval. \n",
            "• Handled customer queries and issues and provided efficient customer service.  \n",
            "• Strong understanding of object-oriented JavaScript and HTML. \n",
            "• Design, develop, test and maintenance of application. \n",
            " \n",
            "Environment: Visual Studio 2013, ASP.NET, C#.NET, SQL SERVER, HTML, CSS, JavaScript. \n",
            " \n",
            "Declaration: \n",
            " \n",
            "I hereby declare that the above particulars of facts and information stated are correct to the best of my \n",
            "belief and knowledge. \n",
            "                                                                                                                                                                          Yours Sincerely, \n",
            "                                                                                                                                                     C.ABINAYA \n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Dot Net Developer\",\"company\":\"CKS Solutions\",\"description\":\"Implemented Entity framework in.Net Core to develop API for CareerIn, which supports both mobile and web application. Designed user interface for the application using ASP.Net MVVM Architecture and implemented business logic using C#.Net. Experience with code-first ORMs. Developed an entity framework model and Implemented LINQ for querying, sorting, filtering the complex objects. Object Oriented Programming languages (OOPS) concepts has been used to implement Business logic layer. Tools used for automation are REST API testing from Visual Studio 2019, SQL Server 2019 for backend data management, Postman for manual REST API testing, and Swagger UI for getting model view for APIs. Experience with database backups, restores and recovery models. Used Azure Dev Ops for source control.\", \"startDate\":\"Oct 2021\", \"endDate\":\"Till Date\"}, {\"label\":\"Work Experience\",\"id\":\"experience2\",\"role\":\"Software Developer\",\"company\":\"Shiva Technology Solutions\",\"description\":\"Designed and developed various abstract classes, interfaces, classes to construct the business logic using C# with OOPS implementation. Involved in the technical group that implements organizational level framework changes. Exposed to various stages of Software Development Life Cycle on Client/Server, Multi-tired and Web- based applications. Implemented the business rules using the Stored procedures in SQL Server to improve the performance. Used Asp.Net validation controls for Client-side validation of server controls. Done Code review and provide feedback to dev and QA work within team. Designed and Effectively Implemented the State Management to improve the performance of the application. Developed and supported application systems in accordance with established standards and processes.\"}]}\n",
            "\n",
            "JSON decoding error: Expecting value: line 2 column 1 (char 1)\n",
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "C.ABINAYA, B.E \n",
            "DOT NET DEVELOPER \n",
            "(abinayachandran1997@gmail.com, 6369387648) \n",
            " \n",
            "Professional Summary: \n",
            " \n",
            "• 4 years of experience in Software Development Life Cycle (SDLC) involving Requirement Gathering, \n",
            "Analysis, Logical and Physical Architectural Modeling, Design, Development, Testing, Implementation, \n",
            "Deployment and Production Support. \n",
            "• Worked on agile methodology to meet timelines with quality deliverables. \n",
            "• Able to work as a team player as well as individually. Highly organized, dedicated with a positive attitude \n",
            "along with the strong analytical and trouble shooting skills. \n",
            "• Worked with business directly taking inputs for implementing new functionalities or modifying existing \n",
            "features as needed. \n",
            "• Experienced in working with dev, database admins, deployment team and managers for getting task \n",
            "done on timely fashion. \n",
            "• Adept at working on multiple projects simultaneously. \n",
            "• Good communication skills, team player. \n",
            " \n",
            "Education: \n",
            "• Bachelor of Engineering, Vins Christian College of Engineering, Tamil Nadu, India. Years: March 2013 – \n",
            "May 2017. \n",
            " \n",
            "Certification: \n",
            "• Certification in C# Software Development, CKS Solutions. \n",
            "• Certification in Asp.net Web Development, Shiva Technology Solutions. \n",
            " \n",
            "Technical Skills: \n",
            "• \n",
            "Backend                                              : \n",
            "DOT NET Core, Web API, C #, ADO.NET, LINQ, Entity Framework. \n",
            "• Markup Languages                      : \n",
            "HTML, JSON. \n",
            "• Styles                                             : \n",
            "CSS3. \n",
            "• Database                                       :  \n",
            "MSSQL Server. \n",
            "• \n",
            "Version Controls                               :          Github, Azure Dev Ops. \n",
            "• Development Tools                     : \n",
            "MS Visual Studio, SQL Server Management  Studio. \n",
            " \n",
            "Professional Experiences: \n",
            " \n",
            "Employer: CKS Solutions \n",
            "Position: Dot Net Developer \n",
            "                   Oct 2021 – Till Date \n",
            "Location: Nagercoil. \n",
            " \n",
            " \n",
            "Project: CareerIn \n",
            "Responsibilities: \n",
            "• Implemented Entity framework in .Net Core to develop API for CareerIn, which supports both mobile \n",
            "and web application. \n",
            "• Designed user interface for the application using ASP.Net MVVM Architecture and implemented \n",
            "business logic using C#.Net. \n",
            "• Experience with code-first ORMs. \n",
            " \n",
            "• Developed an entity framework model and Implemented LINQ for querying, sorting, filtering the \n",
            "complex objects. \n",
            "• Object Oriented Programming languages (OOPS) concepts has been used to implement Business logic \n",
            "layer. \n",
            "• Tools used for automation are REST API testing from Visual Studio 2019, SQL Server 2019 for backend \n",
            "data management, Postman for manual REST API testing, and Swagger UI for getting model view for \n",
            "APIs. \n",
            "• Experience with database backups, restores and recovery models. \n",
            "• Used Azure Dev Ops for source control. \n",
            " \n",
            "Environment: Visual Studio 2019, .NET Core, Entity Framework, LINQ, C#.NET, SQL, Azure Dev Ops. \n",
            " \n",
            "Project: Yamaha Customer Loyalty Administration  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Responsibilities: \n",
            "• Implemented Entity framework in .Net Core to develop API for Yamaha Customer Loyalty \n",
            "Administration, which supports both mobile and web application. \n",
            "• Had good collaboration with front-end developers in order to build the structure of the website. \n",
            "• Object Oriented Programming languages (OOPS) concepts has been used to implement Business logic \n",
            "layer. \n",
            "• Designed user interface for the application using ASP.Net MVVM Architecture and implemented \n",
            "business logic using C#.Net. \n",
            "• Experience with code-first ORMs. \n",
            "• Provided API/Web Services endpoint automation. \n",
            "• Tools used for automation are REST API testing from Visual Studio 2019, SQL Server 2019 for backend \n",
            "data management, Postman for manual REST API testing, and Swagger UI for getting model view for \n",
            "APIs. \n",
            "• Developed an entity framework model and Implemented LINQ for querying, sorting, filtering the \n",
            "complex objects. \n",
            "• Provided QA support by involving in technical discussions, providing a test plan, automating and \n",
            "executing the test cases. \n",
            "• Implemented security settings in IIS. \n",
            "• Used GIT for repository control and Azure Dev Ops for source control. \n",
            " \n",
            "Environment: Visual Studio 2019, .NET Core, ADO.NET, Entity Framework, LINQ, C#.NET, SQL, Azure Dev Ops. \n",
            " \n",
            "Project: WeTeams \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Responsibilities: \n",
            "• All the layers of the application developed using C# and .NET Core. \n",
            "• Business logic layer implemented by Object Oriented Programming Languages (OOPS) concepts. \n",
            "• Strong experience in programming with .NET Framework using C#, ADO.NET, Entity Framework, \n",
            "ASP.NET, Visual Studio 2019, SQL Server 2019. \n",
            "• Implemented LINQ Query operations like Grouping, Ordering and Filtering operations to access database \n",
            "for search of drivers and packages. \n",
            "• Using Entity framework with Automapper for mapping entities to Database objects. \n",
            "• Implemented security settings in IIS. \n",
            "• Designed user interface for the application using ASP.Net MVC and implemented business logic using \n",
            "C#.Net. \n",
            "• Using GIT for repository control and Azure Dev Ops for source control. \n",
            "• Implemented Cron job scheduler to run API automatically. \n",
            "• Involved in investigating the test failures and fixing the automation tests and filing any bugs if discovered. \n",
            "• JWT Token authorization for all API calls for security purpose. \n",
            " \n",
            "Environment: Visual Studio 2019, .NET Core, ADO.NET, C#.NET, SQL, GitHub. \n",
            "Employer: Shiva Technology Solutions \n",
            "Position: Software Developer \n",
            "               May 2018 – Sep 2021 \n",
            "Location: Nagercoil \n",
            " \n",
            " \n",
            "Project: AKIS  \n",
            " \n",
            " \n",
            "  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Responsibilities: \n",
            "• Designed and developed various abstract classes, interfaces, classes to construct the business logic using \n",
            "C# with OOPS implementation. \n",
            "• Involved in the technical group that implements organizational level framework changes. \n",
            "• Exposed to various stages of Software Development Life Cycle on Client/Server, Multi-tired and Web-\n",
            "based applications. \n",
            "• Implemented the business rules using the Stored procedures in SQL Server to improve the performance. \n",
            "• Used Asp.Net validation controls for Client-side validation of server controls. \n",
            "• Done Code review and provide feedback to dev and QA work within team. \n",
            "• Designed and Effectively Implemented the State Management to improve the performance of the \n",
            "application. \n",
            "• Developed and supported application systems in accordance with established standards and processes. \n",
            " \n",
            "Environment: Visual Studio 2013, Asp .Net, C#.NET, SQL SERVER, HTML, CSS, JavaScript. \n",
            " \n",
            "Project: Human Well Being System  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "Responsibilities: \n",
            "• Effectively designed and Implemented the State Management to improve the performance of the \n",
            "application. \n",
            "• Used ASP.NET with C# while developing the web forms to meet the user requirements. \n",
            "• Involved in the technical group that implements organizational level framework changes. \n",
            "• Involved in the design of database, developed Packages and Stored Procedures using SQL. \n",
            "• Business logic layer has been implemented by Object Oriented Programming (OOPS) Concepts. \n",
            "• Implemented reporting application for information retrieval. \n",
            "• Handled customer queries and issues and provided efficient customer service.  \n",
            "• Strong understanding of object-oriented JavaScript and HTML. \n",
            "• Design, develop, test and maintenance of application. \n",
            " \n",
            "Environment: Visual Studio 2013, ASP.NET, C#.NET, SQL SERVER, HTML, CSS, JavaScript. \n",
            " \n",
            "Declaration: \n",
            " \n",
            "I hereby declare that the above particulars of facts and information stated are correct to the best of my \n",
            "belief and knowledge. \n",
            "                                                                                                                                                                          Yours Sincerely, \n",
            "                                                                                                                                                     C.ABINAYA \n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Dot Net Developer\",\"company\":\"CKS Solutions\",\"description\":\"Implemented Entity framework in.Net Core to develop API for CareerIn, which supports both mobile and web application. Designed user interface for the application using ASP.Net MVVM Architecture and implemented business logic using C#.Net. Experience with code-first ORMs. Developed an entity framework model and Implemented LINQ for querying, sorting, filtering the complex objects. Object Oriented Programming languages (OOPS) concepts has been used to implement Business logic layer. Tools used for automation are REST API testing from Visual Studio 2019, SQL Server 2019 for backend data management, Postman for manual REST API testing, and Swagger UI for getting model view for APIs. Experience with database backups, restores and recovery models. Used Azure Dev Ops for source control.\", \"startDate\":\"Oct 2021\", \"endDate\":\"Till Date\"}, {\"label\":\"Work Experience\",\"id\":\"experience2\",\"role\":\"Software Developer\",\"company\":\"Shiva Technology Solutions\",\"description\":\"Designed and developed various abstract classes, interfaces, classes to construct the business logic using C# with OOPS implementation. Involved in the technical group that implements organizational level framework changes. Exposed to various stages of Software Development Life Cycle on Client/Server, Multi-tired and Web- based applications. Implemented the business rules using the Stored procedures in SQL Server to improve the performance. Used Asp.Net validation controls for Client-side validation of server controls. Done Code review and provide feedback to dev and QA work within team. Designed and Effectively Implemented the State Management to improve the performance of the application. Developed and supported application systems in accordance with established standards and processes.\"}]}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "SKILLS\n",
            "INTERESTS\n",
            "CONTACT ME\n",
            "EDUCATION\n",
            "WORK EXPERIENCE\n",
            "ACCOMPLISHMENTS\n",
            "ACADAMIC PROJECTS\n",
            "+91 6379925742\n",
            "abinesharavindhs02@gmail.com\n",
            "Kurumpanai, Kanyakumari\n",
            "Tamil Nadu, India.\n",
            "LinkedIn\n",
            "https://www.linkedin.com/in/abin\n",
            "esh-aravindh-s-3a2\n",
            "Data Analytics\n",
            "Data Structure\n",
            "Cloud Computing\n",
            "Data Science\n",
            "Runing\n",
            "Sports Games\n",
            "Python\n",
            "JAVA\n",
            "MYSQL\n",
            "HTML\n",
            "CSS\n",
            "DATA STRUCTURE\n",
            "OOPS CONCEPTS\n",
            "POWER Bi\n",
            "DATA SCIENCE\n",
            "C\n",
            "National service scheme volunteer in school and college\n",
            "Bachelor's in Computer Science And Engineering\n",
            "University College of Engineering - Nagercoil\n",
            "Academic Score 77%\n",
            "Higher Education 12th\n",
            "St. Ignatius Higher Secondary School - Kurumpanai, Kanyakumari\n",
            "Academic Score 93%\n",
            "10th\n",
            "St.Ignatius Higher Secondary School - Kurumpanai, Kanyakumari\n",
            "Academic Score 96%\n",
            "Yet to explore successful work experience by try lot fail lot and learn lot\n",
            "LOCATION-BASED ALERT SYSTEM FOR DISEASE AND DISASTER\n",
            "USING GEOFENCING\n",
            "This alert system will alert the peoples who are near or inside the disease\n",
            "or disaster zone. It will alert the people within the short period . The tech\n",
            "stack includes React Js, Node JS and Mongo DB.\n",
            "HAMM MUSICAL ACADEMY\n",
            "It contains the all competition details and information for the all\n",
            "independent musicians,singers and dancers. The tech stack includes\n",
            "html, css and php\n",
            "ONLINE BANKING SYSTEM\n",
            "This system will do the all banking operations from our home This\n",
            "techstack includes html, css and php.\n",
            "T o  b e  p a r t  o f  a n  e n t h u s i a s t i c  w o r k \n",
            "e n v i r o n m e n t ,  w h e r e  I  c a n  u s e  m y  t e c h n i c a l\n",
            "s k i l l s  t o  a c c o m p l i s h  o r g a n i z a t i o n a l  g o a l s .\n",
            "Abinesh\n",
            "Aravindh S\n",
            "2018 - 2022\n",
            "2016-2017\n",
            "2014-2015\n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"N/A\",\"description\":\"Worked on developing location-based alert system for disease and disaster using React Js, Node JS and Mongo DB. Also worked on HAMM Musical Academy which contains all competition details and information for independent musicians, singers and dancers using HTML, CSS and PHP. Tried to be part of an enthuastic work environment where he can use his technical skills to accomplish or organizational goals.\", \"startDate\":\"2018\",\"endDate\":\"2022\"}]}\n",
            "\n",
            "JSON decoding error: Expecting value: line 2 column 1 (char 1)\n",
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "SKILLS\n",
            "INTERESTS\n",
            "CONTACT ME\n",
            "EDUCATION\n",
            "WORK EXPERIENCE\n",
            "ACCOMPLISHMENTS\n",
            "ACADAMIC PROJECTS\n",
            "+91 6379925742\n",
            "abinesharavindhs02@gmail.com\n",
            "Kurumpanai, Kanyakumari\n",
            "Tamil Nadu, India.\n",
            "LinkedIn\n",
            "https://www.linkedin.com/in/abin\n",
            "esh-aravindh-s-3a2\n",
            "Data Analytics\n",
            "Data Structure\n",
            "Cloud Computing\n",
            "Data Science\n",
            "Runing\n",
            "Sports Games\n",
            "Python\n",
            "JAVA\n",
            "MYSQL\n",
            "HTML\n",
            "CSS\n",
            "DATA STRUCTURE\n",
            "OOPS CONCEPTS\n",
            "POWER Bi\n",
            "DATA SCIENCE\n",
            "C\n",
            "National service scheme volunteer in school and college\n",
            "Bachelor's in Computer Science And Engineering\n",
            "University College of Engineering - Nagercoil\n",
            "Academic Score 77%\n",
            "Higher Education 12th\n",
            "St. Ignatius Higher Secondary School - Kurumpanai, Kanyakumari\n",
            "Academic Score 93%\n",
            "10th\n",
            "St.Ignatius Higher Secondary School - Kurumpanai, Kanyakumari\n",
            "Academic Score 96%\n",
            "Yet to explore successful work experience by try lot fail lot and learn lot\n",
            "LOCATION-BASED ALERT SYSTEM FOR DISEASE AND DISASTER\n",
            "USING GEOFENCING\n",
            "This alert system will alert the peoples who are near or inside the disease\n",
            "or disaster zone. It will alert the people within the short period . The tech\n",
            "stack includes React Js, Node JS and Mongo DB.\n",
            "HAMM MUSICAL ACADEMY\n",
            "It contains the all competition details and information for the all\n",
            "independent musicians,singers and dancers. The tech stack includes\n",
            "html, css and php\n",
            "ONLINE BANKING SYSTEM\n",
            "This system will do the all banking operations from our home This\n",
            "techstack includes html, css and php.\n",
            "T o  b e  p a r t  o f  a n  e n t h u s i a s t i c  w o r k \n",
            "e n v i r o n m e n t ,  w h e r e  I  c a n  u s e  m y  t e c h n i c a l\n",
            "s k i l l s  t o  a c c o m p l i s h  o r g a n i z a t i o n a l  g o a l s .\n",
            "Abinesh\n",
            "Aravindh S\n",
            "2018 - 2022\n",
            "2016-2017\n",
            "2014-2015\n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"N/A\",\"description\":\"Worked on developing location-based alert system for disease and disaster using React Js, Node JS and Mongo DB. Also worked on HAMM Musical Academy which contains all competition details and information for independent musicians, singers and dancers using HTML, CSS and PHP. Tried to be part of an enthuastic work environment where he can use his technical skills to accomplish or organizational goals.\", \"startDate\":\"2018\",\"endDate\":\"2022\"}]}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "6 months\n",
            "ABIRAMI S\n",
            "Senior Process Associate\n",
            "abhirami.aami@gmail.com \n",
            "\n",
            "9567914106\n",
            "\n",
            "Abhiramam, ARA 171,\n",
            "Edagramam, Karumam PO,\n",
            "Thiruvananthapuram \n",
            "SKILLS\n",
            "Computer Skills,\n",
            "MS Office,\n",
            "Planning,\n",
            "Project Management\n",
            "Skills,\n",
            "Video Creation,\n",
            "Presenting,\n",
            "Social Media Marketing,\n",
            "Flyers\n",
            "and Poster Creation.\n",
            "REFERENCE\n",
            "Aravind Kannan - \"Ecorgy\n",
            "Solutions \"\n",
            "\n",
            "OBJECTIVE\n",
            "To obtain a position that will enable me to use my strong\n",
            "organizational skills, award-winning educational background,\n",
            "and ability to work well with people.\n",
            "\n",
            "EXPERIENCE\n",
            "Ecorgy Solutions\n",
            "Senior Process Associate\n",
            "28 July 2020 - 19 April 2022\n",
            "Working as Senior Process Associate in Revenue Cycle\n",
            "Management Team.\n",
            "Target based works\n",
            "Done some HR Recruiter activities as part of job.\n",
            "EDUCATION\n",
            "Mar Baselios College of Engineering and Technology\n",
            "Electronics and Communication Engineering \n",
            "6.93\n",
            "2020\n",
            "\n",
            "PROJECTS\n",
            "Electromagnetic Radiation Detector\n",
            "This project presents the developed electromagnetic radiation\n",
            "detector system.The prototype of this device employs a\n",
            "rectangular\n",
            "micro strip patch antenna along with a detecting circuitry with\n",
            "a strength display unit.The antenna in this receiver system will\n",
            "detect the radiation from mobile phones and Wi-Fi networks\n",
            "which is 900MHz and 2.4GHz.The circuit is implemented the\n",
            "circuit board that suitable for detecting high frequency\n",
            "applications.This electromagnetic radiation detector can\n",
            "detect the high radiation\n",
            "ABIRAMI S\n",
            "Senior HR Executive\n",
            "aravindkannana@neogencare.co\n",
            "m\n",
            "9446155505\n",
            "WORKSHOPS\n",
            "Undergone workshop on \"Intel\n",
            "Innovation Activity\" conducted by\n",
            "Intel.\n",
            "Undergone workshop on\n",
            "\"Fundamentals of\n",
            "Electromagnetic Engineering and\n",
            "Applications conducted by IEEE\n",
            "APS Kerala chapter and IEEE SB\n",
            "GECBH\n",
            "exposure areas which harms to human body.It also help\n",
            "human to stay away from those radiations up to certain level.\n",
            "\n",
            "ADDITIONAL COURSES\n",
            "Completed course on \"Java Programming and Android\" of\n",
            "duration 6 weeks from CDAC,Technopark,Trivandrum. Done 12\n",
            "weeks online course on \"Fiber optics\" undertaken by NPTEL\n",
            "\n",
            "PERSONAL PROFILE\n",
            "Date of Birth\n",
            ": 17/06/1997\n",
            "Marital Status\n",
            ": Single\n",
            "Nationality\n",
            ": Indian\n",
            "Known Languages : English, Malayalam, Tamil\n",
            "\n",
            "DECLARATION\n",
            "I hereby declare that all the information provided above is\n",
            "accurate to the best of my knowledge.\n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Senior Process Associate\",\"company\":\"Ecorgy Solutions\",\"description\":\"Working as Senior Process Associate in Revenue Cycle Management Team. Target based works Done some HR Recruiter activities as part of job.\",\"startDate\":\"28 July 2020\",\"endDate\":\"19 April 2022\"}]}\n",
            "\n",
            "JSON decoding error: Expecting value: line 2 column 1 (char 1)\n",
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "6 months\n",
            "ABIRAMI S\n",
            "Senior Process Associate\n",
            "abhirami.aami@gmail.com \n",
            "\n",
            "9567914106\n",
            "\n",
            "Abhiramam, ARA 171,\n",
            "Edagramam, Karumam PO,\n",
            "Thiruvananthapuram \n",
            "SKILLS\n",
            "Computer Skills,\n",
            "MS Office,\n",
            "Planning,\n",
            "Project Management\n",
            "Skills,\n",
            "Video Creation,\n",
            "Presenting,\n",
            "Social Media Marketing,\n",
            "Flyers\n",
            "and Poster Creation.\n",
            "REFERENCE\n",
            "Aravind Kannan - \"Ecorgy\n",
            "Solutions \"\n",
            "\n",
            "OBJECTIVE\n",
            "To obtain a position that will enable me to use my strong\n",
            "organizational skills, award-winning educational background,\n",
            "and ability to work well with people.\n",
            "\n",
            "EXPERIENCE\n",
            "Ecorgy Solutions\n",
            "Senior Process Associate\n",
            "28 July 2020 - 19 April 2022\n",
            "Working as Senior Process Associate in Revenue Cycle\n",
            "Management Team.\n",
            "Target based works\n",
            "Done some HR Recruiter activities as part of job.\n",
            "EDUCATION\n",
            "Mar Baselios College of Engineering and Technology\n",
            "Electronics and Communication Engineering \n",
            "6.93\n",
            "2020\n",
            "\n",
            "PROJECTS\n",
            "Electromagnetic Radiation Detector\n",
            "This project presents the developed electromagnetic radiation\n",
            "detector system.The prototype of this device employs a\n",
            "rectangular\n",
            "micro strip patch antenna along with a detecting circuitry with\n",
            "a strength display unit.The antenna in this receiver system will\n",
            "detect the radiation from mobile phones and Wi-Fi networks\n",
            "which is 900MHz and 2.4GHz.The circuit is implemented the\n",
            "circuit board that suitable for detecting high frequency\n",
            "applications.This electromagnetic radiation detector can\n",
            "detect the high radiation\n",
            "ABIRAMI S\n",
            "Senior HR Executive\n",
            "aravindkannana@neogencare.co\n",
            "m\n",
            "9446155505\n",
            "WORKSHOPS\n",
            "Undergone workshop on \"Intel\n",
            "Innovation Activity\" conducted by\n",
            "Intel.\n",
            "Undergone workshop on\n",
            "\"Fundamentals of\n",
            "Electromagnetic Engineering and\n",
            "Applications conducted by IEEE\n",
            "APS Kerala chapter and IEEE SB\n",
            "GECBH\n",
            "exposure areas which harms to human body.It also help\n",
            "human to stay away from those radiations up to certain level.\n",
            "\n",
            "ADDITIONAL COURSES\n",
            "Completed course on \"Java Programming and Android\" of\n",
            "duration 6 weeks from CDAC,Technopark,Trivandrum. Done 12\n",
            "weeks online course on \"Fiber optics\" undertaken by NPTEL\n",
            "\n",
            "PERSONAL PROFILE\n",
            "Date of Birth\n",
            ": 17/06/1997\n",
            "Marital Status\n",
            ": Single\n",
            "Nationality\n",
            ": Indian\n",
            "Known Languages : English, Malayalam, Tamil\n",
            "\n",
            "DECLARATION\n",
            "I hereby declare that all the information provided above is\n",
            "accurate to the best of my knowledge.\n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Senior Process Associate\",\"company\":\"Ecorgy Solutions\",\"description\":\"Working as Senior Process Associate in Revenue Cycle Management Team. Target based works Done some HR Recruiter activities as part of job.\",\"startDate\":\"28 July 2020\",\"endDate\":\"19 April 2022\"}]}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "ADARSH S\n",
            "Email: adarshsasikumar9@gmail.com\n",
            "Phone: 9526007927\n",
            "Sruthi Nediyakala Elavumthitta P O\n",
            "Pathanamthitta\n",
            "Career Objective\n",
            "Intend to build a career with leading corporate of hi-techenvironment with committed \n",
            "& dedicated people,which will help me to explore myself fully and realize my potential.\n",
            "Willing to work as a keyplayerinchallenging and creative environment.\n",
            "Work Experience\n",
            "System Officer - Contract Basis\n",
            "District Court Pathanamthitta\n",
            "Jun, 2022 - Present\n",
            "Assist the district court in CIS system management and administration.\n",
            "The district court and sub divisional court has been fully computerised and working on CIS\n",
            "system.\n",
            "eCourt services to provide efficient and time bound service delivery.\n",
            "Kiosk machine is installed at court to facilitate the public for information of the cases.\n",
            "Systems are provided to all officers on their usage on Ubuntu(Linux) Operating system.\n",
            "To develop ,install & implement decision support systems in courts.\n",
            "Problem solving ,systems configuration and technical issues.\n",
            "Maintain and support users throught a helpdesk service.\n",
            "Assist with processes relating to systems upgrades, formulating troubleshooting and system\n",
            "upgrade and documenting the configuration of the systems.\n",
            "Web Developer\n",
            "Insibe Technologies\n",
            "Aug, 2017 - Dec, 2019\n",
            "Working with team members to come up with new concepts & product analysis\n",
            "Building quality websites and applications with HTML,CSS and Java Script.\n",
            "Analytical skills\n",
            "Responsive design skills\n",
            "Interpersonal skills\n",
            "Testing and debugging skills\n",
            "Back-end basics\n",
            "Search engine optimization\n",
            "Business Development\n",
            "Veristics Technologies\n",
            "Aug, 2014 - Jan, 2017\n",
            "Collaborated with business development, marketing, and product departments on the creation\n",
            "of competitive concept proposals.\n",
            "Developed new service offerings based on detailed and documented insights of market and\n",
            "client needs.\n",
            "Built and maintained relationships with key contacts at potential clients, consulting companies\n",
            "and partners in order to get access to new opportunities.\n",
            "E- Commerce solutions\n",
            "Communication Skills and Team Work\n",
            "Creative Thinking\n",
            "Flexibility and Adaptablility\n",
            "Social Media\n",
            "Dot Net Developer Trainee\n",
            "I-Net\n",
            "Oct, 2013 - Mar, 2014\n",
            "Education Details\n",
            "B.Tech Computer Science\n",
            "Mount Zion College of Engineering Kadammanitta\n",
            "Year of completion: 2013\n",
            "Marks: 60%\n",
            "10th\n",
            "SVGVHSS KIDAGANOOR\n",
            "Year of completion: 2007\n",
            "Marks: 68%\n",
            "12th\n",
            "PHSS MEZHUVELI\n",
            "Year of completion: 2009\n",
            "Marks: 70%\n",
            "Technical Skills\n",
            "Ubuntu\n",
            "VMware ESXi\n",
            "Kavach Authentication\n",
            "Troubleshoot\n",
            "Problem Solving Administration\n",
            "Network Virtualization\n",
            "Cloud Architecture\n",
            "Security and Monitoring\n",
            "BootStrap,(MySQL, MongoDB, PostgreSQL)\n",
            "MVC, Core PHP\n",
            "PHP/PERL/Access\n",
            "Oracle/.NET/Css\n",
            "Asp/SQL/Java script\n",
            "Visual Basic\n",
            "XML/C#/Ajax/HTML\n",
            "Wordpress\n",
            "Dream weaver\n",
            "Projects\n",
            "Cloud Computing\n",
            "Technologies : C#, Dot Net, MS SQL Server 2008\n",
            "Anakest\n",
            "Technologies : PHP\n",
            ", HTML,Java Script, Css,MS SQL Server 2008\n",
            "Elixier Environ Systems\n",
            "Technologies : PHP\n",
            ", HTML,Java Script, Css,MS SQL Server 2008\n",
            "Muhamoon-Attorneys &Legal Advisers\n",
            "Technologies : PHP\n",
            ", HTML,Java Script, Css,MS SQL Server 2008\n",
            "Interests/Hobbies\n",
            "Traveling, Music\n",
            "Personal Details\n",
            "DOB : 30-10-1991\n",
            "Languages Known : English,Malayalam\n",
            "Nationality : Indian\n",
            "Declaration\n",
            "I here by declare that the above mentioned informations are true up to my knowledge and I hear the\n",
            "responsibility for the correctness of above mentioned informations.\n",
            "Date:\n",
            "Place: Pathanamthitta\n",
            "ADARSH S\n",
            "\n",
            "\n",
            "Answer:\n",
            "{\n",
            "\"entities\": [\n",
            "{\n",
            "\"label\": \"Work Experience\",\n",
            "\"id\": \"experience1\",\n",
            "\"role\": \"System Officer\",\n",
            "\"company\": \"District Court Pathanamthitta\",\n",
            "\"description\": \"Assist the district court in CIS system management and administration. The district court and sub divisional court has been fully computerised and working on CIS system. eCourt services to provide efficient and time bound service delivery. Kiosk machine is installed at court to facilitate the public for information of the cases. Systems are provided to all officers on their usage on Ubuntu(Linux) Operating system. To develop,install & implement decision support systems in courts. Problem solving,systems configuration and technical issues. Maintain and support users throught a helpdesk service. Assist with processes relating to systems upgrades, formulating troubleshooting and system upgrade and documenting the configuration of the systems.\",\n",
            "\"startDate\": \"Jun, 2022\",\n",
            "\"endDate\": \"Present\"\n",
            "},\n",
            "{\n",
            "\"label\": \"Work Experience\",\n",
            "\"id\": \"experience2\",\n",
            "\"role\": \"Web Developer\",\n",
            "\"company\": \"Insibe Technologies\",\n",
            "\"description\": \"Working with team members to come up with new concepts & product analysis. Building quality websites and applications with HTML,CSS and Java Script. Analytical skills. Responsive design skills. Interpersonal skills. Testing and debugging skills. Back-end basics. Search engine optimization.\",\n",
            "\"startDate\": \"Aug, 2017\",\n",
            "\"endDate\": \"Dec, 2019\"\n",
            "},\n",
            "{\n",
            "\"label\": \"Work Experience\",\n",
            "\"id\": \"experience3\",\n",
            "\"role\": \"Business Development\",\n",
            "\"company\": \"Veristics Technologies\",\n",
            "\"description\": \"Collaborated with business development, marketing, and product departments on the creation of competitive concept proposals. Developed new service offerings based on detailed and documented insights of market and client needs. Built and maintained relationships with key contacts at potential clients, consulting companies and partners in order to get access to new opportunities.\",\n",
            "\"startDate\": \"Aug, 2014\",\n",
            "\"endDate\": \"Jan, 2017\"\n",
            "},\n",
            "{\n",
            "\"label\": \"Work Experience\",\n",
            "\"id\": \"experience4\",\n",
            "\"role\": \"Dot Net Developer Trainee\",\n",
            "\"company\": \"I-Net\",\n",
            "\"description\": \"\",\n",
            "\"startDate\": \"Oct, 2013\",\n",
            "\"endDate\": \"Mar, 2014\"\n",
            "}\n",
            "]\n",
            "}\n",
            "\n",
            "JSON decoding error: Expecting value: line 2 column 1 (char 1)\n",
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "ADARSH S\n",
            "Email: adarshsasikumar9@gmail.com\n",
            "Phone: 9526007927\n",
            "Sruthi Nediyakala Elavumthitta P O\n",
            "Pathanamthitta\n",
            "Career Objective\n",
            "Intend to build a career with leading corporate of hi-techenvironment with committed \n",
            "& dedicated people,which will help me to explore myself fully and realize my potential.\n",
            "Willing to work as a keyplayerinchallenging and creative environment.\n",
            "Work Experience\n",
            "System Officer - Contract Basis\n",
            "District Court Pathanamthitta\n",
            "Jun, 2022 - Present\n",
            "Assist the district court in CIS system management and administration.\n",
            "The district court and sub divisional court has been fully computerised and working on CIS\n",
            "system.\n",
            "eCourt services to provide efficient and time bound service delivery.\n",
            "Kiosk machine is installed at court to facilitate the public for information of the cases.\n",
            "Systems are provided to all officers on their usage on Ubuntu(Linux) Operating system.\n",
            "To develop ,install & implement decision support systems in courts.\n",
            "Problem solving ,systems configuration and technical issues.\n",
            "Maintain and support users throught a helpdesk service.\n",
            "Assist with processes relating to systems upgrades, formulating troubleshooting and system\n",
            "upgrade and documenting the configuration of the systems.\n",
            "Web Developer\n",
            "Insibe Technologies\n",
            "Aug, 2017 - Dec, 2019\n",
            "Working with team members to come up with new concepts & product analysis\n",
            "Building quality websites and applications with HTML,CSS and Java Script.\n",
            "Analytical skills\n",
            "Responsive design skills\n",
            "Interpersonal skills\n",
            "Testing and debugging skills\n",
            "Back-end basics\n",
            "Search engine optimization\n",
            "Business Development\n",
            "Veristics Technologies\n",
            "Aug, 2014 - Jan, 2017\n",
            "Collaborated with business development, marketing, and product departments on the creation\n",
            "of competitive concept proposals.\n",
            "Developed new service offerings based on detailed and documented insights of market and\n",
            "client needs.\n",
            "Built and maintained relationships with key contacts at potential clients, consulting companies\n",
            "and partners in order to get access to new opportunities.\n",
            "E- Commerce solutions\n",
            "Communication Skills and Team Work\n",
            "Creative Thinking\n",
            "Flexibility and Adaptablility\n",
            "Social Media\n",
            "Dot Net Developer Trainee\n",
            "I-Net\n",
            "Oct, 2013 - Mar, 2014\n",
            "Education Details\n",
            "B.Tech Computer Science\n",
            "Mount Zion College of Engineering Kadammanitta\n",
            "Year of completion: 2013\n",
            "Marks: 60%\n",
            "10th\n",
            "SVGVHSS KIDAGANOOR\n",
            "Year of completion: 2007\n",
            "Marks: 68%\n",
            "12th\n",
            "PHSS MEZHUVELI\n",
            "Year of completion: 2009\n",
            "Marks: 70%\n",
            "Technical Skills\n",
            "Ubuntu\n",
            "VMware ESXi\n",
            "Kavach Authentication\n",
            "Troubleshoot\n",
            "Problem Solving Administration\n",
            "Network Virtualization\n",
            "Cloud Architecture\n",
            "Security and Monitoring\n",
            "BootStrap,(MySQL, MongoDB, PostgreSQL)\n",
            "MVC, Core PHP\n",
            "PHP/PERL/Access\n",
            "Oracle/.NET/Css\n",
            "Asp/SQL/Java script\n",
            "Visual Basic\n",
            "XML/C#/Ajax/HTML\n",
            "Wordpress\n",
            "Dream weaver\n",
            "Projects\n",
            "Cloud Computing\n",
            "Technologies : C#, Dot Net, MS SQL Server 2008\n",
            "Anakest\n",
            "Technologies : PHP\n",
            ", HTML,Java Script, Css,MS SQL Server 2008\n",
            "Elixier Environ Systems\n",
            "Technologies : PHP\n",
            ", HTML,Java Script, Css,MS SQL Server 2008\n",
            "Muhamoon-Attorneys &Legal Advisers\n",
            "Technologies : PHP\n",
            ", HTML,Java Script, Css,MS SQL Server 2008\n",
            "Interests/Hobbies\n",
            "Traveling, Music\n",
            "Personal Details\n",
            "DOB : 30-10-1991\n",
            "Languages Known : English,Malayalam\n",
            "Nationality : Indian\n",
            "Declaration\n",
            "I here by declare that the above mentioned informations are true up to my knowledge and I hear the\n",
            "responsibility for the correctness of above mentioned informations.\n",
            "Date:\n",
            "Place: Pathanamthitta\n",
            "ADARSH S\n",
            "\n",
            "\n",
            "Answer:\n",
            "{\n",
            "\"entities\": [\n",
            "{\n",
            "\"label\": \"Work Experience\",\n",
            "\"id\": \"experience1\",\n",
            "\"role\": \"System Officer\",\n",
            "\"company\": \"District Court Pathanamthitta\",\n",
            "\"description\": \"Assist the district court in CIS system management and administration. The district court and sub divisional court has been fully computerised and working on CIS system. eCourt services to provide efficient and time bound service delivery. Kiosk machine is installed at court to facilitate the public for information of the cases. Systems are provided to all officers on their usage on Ubuntu(Linux) Operating system. To develop,install & implement decision support systems in courts. Problem solving,systems configuration and technical issues. Maintain and support users throught a helpdesk service. Assist with processes relating to systems upgrades, formulating troubleshooting and system upgrade and documenting the configuration of the systems.\",\n",
            "\"startDate\": \"Jun, 2022\",\n",
            "\"endDate\": \"Present\"\n",
            "},\n",
            "{\n",
            "\"label\": \"Work Experience\",\n",
            "\"id\": \"experience2\",\n",
            "\"role\": \"Web Developer\",\n",
            "\"company\": \"Insibe Technologies\",\n",
            "\"description\": \"Working with team members to come up with new concepts & product analysis. Building quality websites and applications with HTML,CSS and Java Script. Analytical skills. Responsive design skills. Interpersonal skills. Testing and debugging skills. Back-end basics. Search engine optimization.\",\n",
            "\"startDate\": \"Aug, 2017\",\n",
            "\"endDate\": \"Dec, 2019\"\n",
            "},\n",
            "{\n",
            "\"label\": \"Work Experience\",\n",
            "\"id\": \"experience3\",\n",
            "\"role\": \"Business Development\",\n",
            "\"company\": \"Veristics Technologies\",\n",
            "\"description\": \"Collaborated with business development, marketing, and product departments on the creation of competitive concept proposals. Developed new service offerings based on detailed and documented insights of market and client needs. Built and maintained relationships with key contacts at potential clients, consulting companies and partners in order to get access to new opportunities.\",\n",
            "\"startDate\": \"Aug, 2014\",\n",
            "\"endDate\": \"Jan, 2017\"\n",
            "},\n",
            "{\n",
            "\"label\": \"Work Experience\",\n",
            "\"id\": \"experience4\",\n",
            "\"role\": \"Dot Net Developer Trainee\",\n",
            "\"company\": \"I-Net\",\n",
            "\"description\": \"\",\n",
            "\"startDate\": \"Oct, 2013\",\n",
            "\"endDate\": \"Mar, 2014\"\n",
            "}\n",
            "]\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "Contact\n",
            "Education\n",
            "Phone: 9061932048\n",
            "adiadithya1212@gmail.com\n",
            "Email\n",
            "Vasantham, Single Street West Lane,\n",
            "Balaramapuram\n",
            "Address\n",
            "Adithya S\n",
            "U A T  T e s t e r\n",
            "I am an ambitious individual who is looking to broaden my testing\n",
            "career. My background lies mostly in, UAT Testing in the e-learning\n",
            "domain. But I'm open to new challenges within any industry and I am\n",
            "willing to work hard to reach my goals. A creative, self-motivated team\n",
            "player with excellent organizational skills which have been used to great\n",
            "effect in achieving targets during my career. Able to work under\n",
            "pressure and remain focused during constant change as well as\n",
            "challenges. Always eager for learning experiences that will enable me to\n",
            "grow professionally.\n",
            "Experience\n",
            "Experience in performing User Acceptance Testing (UAT) on\n",
            "monthly beta releases.\n",
            "Writing test cases on beta releases and platform testing.\n",
            "Experience in performing platform testing using Manual\n",
            "Testing.\n",
            "Mykademy LMS instance creation and account setup for\n",
            "Enterprise and SaaS clients.\n",
            "Created platform instances based on client requirements.\n",
            "Account Management of enterprise clients like Jaguar & Land\n",
            "Rover, Tesco, NOCN, ABE, etc.\n",
            "Identifying upselling opportunities and handing over the\n",
            "account details to Sales Team.\n",
            "Closely working with the Sales Team for the platform demo on\n",
            "client calls.\n",
            "Educating clients to use our knowledgebase and thus reducing\n",
            "the support touch points.\n",
            "Experience in building courses using course builder.\n",
            "Submitting weekly reports and account management reports to\n",
            "Reporting Manager through the Project Management tool\n",
            "Monday.\n",
            "UAT Tester \n",
            "April 2021 - September 2022\n",
            "Mykademy Learning Private Ltd, Technopark Phase 4, Trivandrum\n",
            "Completed Certification Course in Manual Testing from STC\n",
            "Trivandrum(September 2022)\n",
            "Profile Summary\n",
            "Certification\n",
            "Lourdes Matha College of Science &\n",
            "Technology, Kuttichal\n",
            "Shree Vidyadhiraja Vidya Nilayam,\n",
            "Neyyattinkara\n",
            "B-Tech in Computer Science\n",
            "Higher Secondary Education\n",
            "2020\n",
            "2016\n",
            "Zendesk Ticketing Tool\n",
            "MS Office\n",
            "Manual Testing\n",
            "Google Workplace\n",
            "English\n",
            "Malayalam\n",
            "Expertise\n",
            "Languages \n",
            "Tamil\n",
            "Testing Skills\n",
            "Manual Testing\n",
            "Selenium IDE\n",
            "Knowledge in Functional & Non-\n",
            "functional Testing\n",
            "Knowledge in SDLC/STLC\n",
            "phases\n",
            "Knowledge in bug reporting and bug\n",
            "life cycle.\n",
            "Knowledge in Agile Testing\n",
            "Knowledge in Web App testing\n",
            "Knowledge in preparing test\n",
            "scenarios, deriving test cases from\n",
            "test scenarios, and test execution\n",
            "Monday Project Management Tool\n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\", \"id\":\"experience1\", \"role\":\"UAT Tester\", \"company\":\"Mykademy Learning Private Ltd\", \"description\":\"Performed User Acceptance Testing (UAT) on monthly beta releases. Writing test cases on beta releases and platform testing. Created platform instances based on client requirements. Account Management of enterprise clients like Jaguar & Land Rover, Tesco, NOCN, ABE, etc. Identified upselling opportunities and handed over the account details to Sales Team. Closely worked with the Sales Team for the platform demo on client calls. Educated clients to use our knowledgebase and thus reducing the support touch points. Experience in building courses using course builder. Submitted weekly reports and account management reports to Reporting Manager through the Project Management tool Monday.\", \"startDate\":\"April 2021\", \"endDate\":\"September 2022\"}]}\n",
            "\n",
            "JSON decoding error: Expecting value: line 2 column 1 (char 1)\n",
            "Raw output:\n",
            "\n",
            "From the Resume text for a job aspirant below, extract Entities strictly as instructed below\n",
            "1. Look for Work Experience entity type in the text and generate the information defined below:\n",
            "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. NEVER create new entity types that aren't mentioned below. Document must be summarized and stored inside Work Experience entity under `description` property\n",
            "    Entity Definition:\n",
            "    label:'Work Experience',id:string,role:string,company:string,description:string,startDate:string,endDate:string //Work Experience Node\n",
            "2. If you cannot find any information on the entities above, it is okay to return empty value. DO NOT create fictitious data\n",
            "3. Do NOT create duplicate entities or properties\n",
            "4. Strictly extract only Work Experience. No other Entities should be extracted\n",
            "5. DO NOT MISS out any Work Experience related entity\n",
            "6. NEVER Impute missing values\n",
            "Output JSON (Strict):\n",
            "{\"entities\": [{\"label\":\"Work Experience\",\"id\":\"experience1\",\"role\":\"Software Developer\",\"company\":\"ABC Corp\",\"description\":\"Worked on developing web applications using JavaScript and React.\",\"startDate\":\"June 2018\",\"endDate\":\"Present\"}]}\n",
            "\n",
            "Question: Now, extract Work Experience information as mentioned above for the text below -\n",
            "\n",
            "Contact\n",
            "Education\n",
            "Phone: 9061932048\n",
            "adiadithya1212@gmail.com\n",
            "Email\n",
            "Vasantham, Single Street West Lane,\n",
            "Balaramapuram\n",
            "Address\n",
            "Adithya S\n",
            "U A T  T e s t e r\n",
            "I am an ambitious individual who is looking to broaden my testing\n",
            "career. My background lies mostly in, UAT Testing in the e-learning\n",
            "domain. But I'm open to new challenges within any industry and I am\n",
            "willing to work hard to reach my goals. A creative, self-motivated team\n",
            "player with excellent organizational skills which have been used to great\n",
            "effect in achieving targets during my career. Able to work under\n",
            "pressure and remain focused during constant change as well as\n",
            "challenges. Always eager for learning experiences that will enable me to\n",
            "grow professionally.\n",
            "Experience\n",
            "Experience in performing User Acceptance Testing (UAT) on\n",
            "monthly beta releases.\n",
            "Writing test cases on beta releases and platform testing.\n",
            "Experience in performing platform testing using Manual\n",
            "Testing.\n",
            "Mykademy LMS instance creation and account setup for\n",
            "Enterprise and SaaS clients.\n",
            "Created platform instances based on client requirements.\n",
            "Account Management of enterprise clients like Jaguar & Land\n",
            "Rover, Tesco, NOCN, ABE, etc.\n",
            "Identifying upselling opportunities and handing over the\n",
            "account details to Sales Team.\n",
            "Closely working with the Sales Team for the platform demo on\n",
            "client calls.\n",
            "Educating clients to use our knowledgebase and thus reducing\n",
            "the support touch points.\n",
            "Experience in building courses using course builder.\n",
            "Submitting weekly reports and account management reports to\n",
            "Reporting Manager through the Project Management tool\n",
            "Monday.\n",
            "UAT Tester \n",
            "April 2021 - September 2022\n",
            "Mykademy Learning Private Ltd, Technopark Phase 4, Trivandrum\n",
            "Completed Certification Course in Manual Testing from STC\n",
            "Trivandrum(September 2022)\n",
            "Profile Summary\n",
            "Certification\n",
            "Lourdes Matha College of Science &\n",
            "Technology, Kuttichal\n",
            "Shree Vidyadhiraja Vidya Nilayam,\n",
            "Neyyattinkara\n",
            "B-Tech in Computer Science\n",
            "Higher Secondary Education\n",
            "2020\n",
            "2016\n",
            "Zendesk Ticketing Tool\n",
            "MS Office\n",
            "Manual Testing\n",
            "Google Workplace\n",
            "English\n",
            "Malayalam\n",
            "Expertise\n",
            "Languages \n",
            "Tamil\n",
            "Testing Skills\n",
            "Manual Testing\n",
            "Selenium IDE\n",
            "Knowledge in Functional & Non-\n",
            "functional Testing\n",
            "Knowledge in SDLC/STLC\n",
            "phases\n",
            "Knowledge in bug reporting and bug\n",
            "life cycle.\n",
            "Knowledge in Agile Testing\n",
            "Knowledge in Web App testing\n",
            "Knowledge in preparing test\n",
            "scenarios, deriving test cases from\n",
            "test scenarios, and test execution\n",
            "Monday Project Management Tool\n",
            "\n",
            "\n",
            "Answer:\n",
            "{\"entities\": [{\"label\":\"Work Experience\", \"id\":\"experience1\", \"role\":\"UAT Tester\", \"company\":\"Mykademy Learning Private Ltd\", \"description\":\"Performed User Acceptance Testing (UAT) on monthly beta releases. Writing test cases on beta releases and platform testing. Created platform instances based on client requirements. Account Management of enterprise clients like Jaguar & Land Rover, Tesco, NOCN, ABE, etc. Identified upselling opportunities and handed over the account details to Sales Team. Closely worked with the Sales Team for the platform demo on client calls. Educated clients to use our knowledgebase and thus reducing the support touch points. Experience in building courses using course builder. Submitted weekly reports and account management reports to Reporting Manager through the Project Management tool Monday.\", \"startDate\":\"April 2021\", \"endDate\":\"September 2022\"}]}\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-861b666c564b>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mall_entities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresume_texts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_work_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mall_entities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"entities\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-861b666c564b>\u001b[0m in \u001b[0;36mextract_work_experience\u001b[0;34m(resume_text)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_work_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwork_experience_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresume_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mraw_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Raw output:\\n{raw_output}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print raw output for debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    632\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 )\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[0;32m--> 803\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    804\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             output = (\n\u001b[0;32m--> 657\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             responses = self.pipeline(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mbatch_prompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mpipeline_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 )\n\u001b[0;32m-> 1224\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   1759\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2398\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1140\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 )\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1025\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtied_pointers_to_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 set_module_tensor_to_device(\n\u001b[0m\u001b[1;32m    348\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    398\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required packages\n",
        "!pip install langchain langchain-community\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load your custom dataset\n",
        "file_path = '/content/extracted_resumes.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract the text column\n",
        "resume_texts = df.iloc[:, 1].tolist()\n",
        "\n",
        "# Set up the text generation pipeline\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=5000,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.15,\n",
        ")\n",
        "\n",
        "# Use the pipeline with LangChain\n",
        "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0.1})\n",
        "\n",
        "# Define the prompt template for extracting total work experience\n",
        "work_experience_prompt_tpl = \"\"\"\n",
        "From the Resume text below, calculate the total work experience of the candidate. The result should be in years and months.\n",
        "Question: Calculate the total work experience for the text below -\n",
        "\n",
        "{text}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Create the chain for work experience extraction\n",
        "work_experience_prompt_template = PromptTemplate(template=work_experience_prompt_tpl, input_variables=['text'])\n",
        "work_experience_chain = LLMChain(llm=llm, prompt=work_experience_prompt_template)\n",
        "\n",
        "# Function to extract work experience from resume text\n",
        "def extract_work_experience(resume_text):\n",
        "    try:\n",
        "        result = work_experience_chain.invoke({\"text\": resume_text})\n",
        "        return result['text']\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing resume: {e}\")\n",
        "        return None\n",
        "\n",
        "# Run the extraction on all resumes and print the results\n",
        "all_experiences = []\n",
        "for idx, text in enumerate(resume_texts):\n",
        "    print(f\"Processing resume {idx + 1}/{len(resume_texts)}\")\n",
        "    experience = extract_work_experience(text)\n",
        "    if experience:\n",
        "        print(f\"Total Work Experience for resume {idx + 1}: {experience}\")\n",
        "    else:\n",
        "        print(f\"Failed to extract work experience for resume {idx + 1}\")\n",
        "    all_experiences.append(experience)\n",
        "\n",
        "# Print the final results for all resumes\n",
        "print(\"Final extracted work experiences:\")\n",
        "for idx, experience in enumerate(all_experiences):\n",
        "    print(f\"Resume {idx + 1}: {experience}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oecjm9lwFbvC",
        "outputId": "0f928905-186b-478f-9e5d-e4eb74e20113"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.82)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing resume 1/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Work Experience for resume 1: \n",
            "From the Resume text below, calculate the total work experience of the candidate. The result should be in years and months.\n",
            "Question: Calculate the total work experience for the text below -\n",
            "\n",
            "Ajay A \n",
            "JUNIOR-HR \n",
            "ajayasok04@gmail.com                           \n",
            " \n",
            "                             +91-8838543432 \n",
            "                                                                                        \n",
            "  PROFESSIONAL SUMMARY \n",
            " \n",
            "An altruistic and self-motivated person who wish to pursue a career in HR with a progressive \n",
            "organization that provides a scope to combine multidisciplinary skills of human resources and \n",
            "management in a dynamic environment. \n",
            " \n",
            "   PROFESSIONAL EXPERIENCE  \n",
            " \n",
            "JUNIOR-HR ASSOCIATE                                                                                Oct 2021- March 2022 \n",
            "ACHERON SOFTWARE CONSULTANCY PVT LTD                                      (Hyderabad)    \n",
            " \n",
            "     Roles and Responsibilities: \n",
            "• \n",
            "Screen candidates for open job requirements. \n",
            "• \n",
            "Conduct phone Interviews and in person interviews. \n",
            "• \n",
            "Follow up candidates for the interview and offers. \n",
            "• \n",
            "Supporting Talent acquisition team for sourcing profiles from various job portals \n",
            "(Naukri,Linkedin jobs etc). \n",
            "• \n",
            "Managing Calendar and roll out Google forms for the performance and training feedbacks. \n",
            "• \n",
            "Organize internal events as a part of company culture bonding employees. \n",
            "• \n",
            "Recommend new approaches, policies and procedure to improve the effectiveness. \n",
            "• \n",
            "Implemented new HRMS Software (KEKA) for free flow of HR- operations. \n",
            "• \n",
            "Maintaining Employee database, attendance & leave management through the HR portal. \n",
            "• \n",
            "Organize ergonomic session for employees to maintain the working    posture and keeping the \n",
            "environment healthy. \n",
            "• \n",
            "Empathy program for the better cultural bonding and growth of the organization. \n",
            "• \n",
            "Scheduling interviews and rolling out offers, Salary negotiations, on- boarding and orientation. \n",
            "• \n",
            "Managing resources by allocating to project managers. \n",
            "• \n",
            "Sourcing Training programs for employees. \n",
            "• \n",
            "Employee retention. \n",
            "• \n",
            "Organizing Company annual kick-off event by sourcing the venue and negotiating the financial \n",
            "standards. \n",
            "• \n",
            "Supporting Immigration and Visa process to the CEO and Managers for Business trips. \n",
            "• \n",
            "Supporting Admin in maintaining the People availability form and employee directory in MS \n",
            "excel. \n",
            "• \n",
            "Organize Outdoor activities for a better bonding between the peers. \n",
            " \n",
            " HUMAN RESOURCE BUSINESS PARTNER                                            March 2021 – Sept 2021 \n",
            " KRISHNAA ENTERPRISES                                                                                     (Coimbatore) \n",
            "     Roles and Responsibilities: \n",
            "• \n",
            "Improving and monitoring employee productivity. \n",
            "• \n",
            "Structuring compensation and benefit packages. \n",
            "• \n",
            "Managing staff wellness initiatives. \n",
            "• \n",
            "Improving relations between staff and employers. \n",
            "• \n",
            "Building relationships and finding resources for the labor requirements. \n",
            "• \n",
            "Strategically retaining customers by being flexible and negotiating. \n",
            "• \n",
            "Convincing and consulting customer grievances. \n",
            "• \n",
            "Assisted with administration and operations for a fast-paced retail business. \n",
            " \n",
            "         BUSINESS DEVELOPMENT ASSOCIATE                                       June 2017 – Feb 2021 \n",
            "         KRISHNAA ENTERPRISES                                                                        (Coimbatore) \n",
            "        Roles and Responsibilities: \n",
            " \n",
            "• \n",
            "Quality control and assurance. \n",
            "• \n",
            "Negotiating with labors in production of finished goods. \n",
            "• \n",
            "Organized the transshipment of materials from end to end. \n",
            "• \n",
            "Identify new business opportunities. \n",
            "• \n",
            "Cultivating strong relationships with new clients, while maintaining existing client relationships. \n",
            "• \n",
            "Ability to manage multiple projects concurrently and meet deadlines. \n",
            "• \n",
            "Demonstrate strong interpersonal skills with the ability to engage labors effectively. \n",
            "• \n",
            "Material management in various grade metals like stainless steel (SS304, 316,410etc.) \n",
            " \n",
            "   KEY COMPETENCIES \n",
            "• \n",
            "Microsoft Word, Excel, Power point. \n",
            "• \n",
            "Google Calendar, Sheets, Slides. \n",
            "• \n",
            "KEKA HRMS Software. \n",
            "• \n",
            "Job Portals. \n",
            "TRAINING & CERTIFICATONS \n",
            "• \n",
            "MS- Office. \n",
            "• \n",
            "Talent Acquisition & Hiring (Udemy). \n",
            "• \n",
            "SAP-HR Beginners (Udemy). \n",
            "EDUCATION \n",
            "MBA - CMS INSTITUTE OF MANAGEMENT STUDIES                                           April-2017        \n",
            "      HR & Logistics - 69%.                                                                                                      Coimbatore \n",
            "B.A - CMS COLLEGE OF SCIENCE & COMMERCE                                                   April-2015 \n",
            "     English Literature - 66%                                                                                                   Coimbatore \n",
            "   PERSONAL INFORMATION \n",
            "Marital Status: Single \n",
            "Date of Birth: 08-July-1995 \n",
            "   LANGUAGE PROFICIENCY \n",
            "English| Hindi| Tamil| Malayalam \n",
            "HOBBIES AND INTEREST \n",
            "• \n",
            "Being a football player since childhood, I love sports. I always want myself to be fit and sporty. \n",
            "• \n",
            "Love Singing. \n",
            "• \n",
            "Love to draw and paint. \n",
            " \n",
            "DECLARATION \n",
            "I hereby declare that the contents of my resume are accurate to the best of my knowledge and verify their \n",
            "authenticity. \n",
            "\n",
            "\n",
            "Answer:\n",
            "The total work experience for the given resume is approximately 4 years and 9 months (from February 2017 to March 2022). This calculation includes the duration of the three mentioned roles: Business Development Associate (June 2017 – Feb 2021), Human Resource Business Partner (March 2021 – Sept 2021), and Junior-HR Associate (Oct 2021- March 2022).\n",
            "Processing resume 2/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Work Experience for resume 2: \n",
            "From the Resume text below, calculate the total work experience of the candidate. The result should be in years and months.\n",
            "Question: Calculate the total work experience for the text below -\n",
            "\n",
            "Abid Ibrahim \n",
            "Developer/Blockchain Enthusiast \n",
            "abidibrahim3304@gmail.com \n",
            "+91 7012847450 \n",
            "Kozhikode, India \n",
            "linkedin.com/in/abid-ibrahim-229886191 \n",
            "github.com/Abid-Ibrahim \n",
            "EDUCATION \n",
            "Bachelor’s Degree in Information\n",
            "Technology \n",
            "Cochin University of Science And\n",
            "Technology \n",
            "08/2019 - Present,  \n",
            "Primary Education \n",
            "St.Mary's English Medium School \n",
            "2004 - 2016,  \n",
            "ICSE Board -90.6% \n",
            "Higher Secondary Education \n",
            "Silver Hills Public School \n",
            "2016 - 2018,  \n",
            "CBSE Board - 82.8 \n",
            "WORK EXPERIENCE \n",
            "Intern/Trainee \n",
            "Homomorphic Solutions \n",
            "02/2022 - Present,  \n",
            "SKILLS \n",
            "Python \n",
            "React.js \n",
            "C++ \n",
            "Communication Skills \n",
            "Typescript \n",
            "SQL \n",
            "Git \n",
            "Teamwork \n",
            "PERSONAL PROJECTS \n",
            "Chiliagon DAO Website \n",
            "https://chiliagondao.on.ﬂeek.co/ \n",
            "College Management System \n",
            "https://github.com/Abid-Ibrahim/college-management-system \n",
            "Quit Smoke App \n",
            "https://github.com/Abid-Ibrahim/Quit-Smoke-App \n",
            "CERTIFICATES \n",
            "Python Certiﬁcate (03/2022 - Present) \n",
            "https://www.kaggle.com/learn/certiﬁcation/abid19/python \n",
            "30 Days of Google Cloud 2021 \n",
            "https://drive.google.com/ﬁle/d/1_WP2X4C39DSRLlDzp_Y7mi7T3ci6Yea\n",
            "m/view?usp=sharing \n",
            "LANGUAGES \n",
            "English \n",
            "Native or Bilingual Proﬁciency \n",
            "Malayalam \n",
            "Native or Bilingual Proﬁciency \n",
            "Hindi \n",
            "Native or Bilingual Proﬁciency \n",
            "INTERESTS \n",
            "Coding \n",
            "Football \n",
            "Crypto \n",
            "Reading \n",
            "\n",
            "\n",
            "Answer:\n",
            "The candidate has been working as an Intern/Trainee at Homomorphic Solutions since February 2022. Before that, there is no mention of any work experience. So, the total work experience would be approximately 1 year and 1 month (from February 2022 to the date of resume submission). However, without knowing the exact date of resume submission, we can't provide a precise calculation.\n",
            "Processing resume 3/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Work Experience for resume 3: \n",
            "From the Resume text below, calculate the total work experience of the candidate. The result should be in years and months.\n",
            "Question: Calculate the total work experience for the text below -\n",
            "\n",
            "   ABIJITH K                        \n",
            "  \n",
            "Mobile: +91-9745493045  \n",
            "Email: abijithk539@gmail.com  \n",
            "OBJECTIVE  \n",
            "• \n",
            "Looking for a challenging career which demands the best of my professional ability in terms of \n",
            "technical and analytical skills, and helps me in broadening and enhancing my current skill and \n",
            "knowledge.  \n",
            "• \n",
            "To learn from the challenges in the industry and make myself capable to face new challenge.  \n",
            "EDUCATION  \n",
            "• \n",
            "Bachelor of Commerce in Computer Application  \n",
            "               University of Calicut  \n",
            "               2017-2020 \n",
            "• \n",
            "Plus Two \n",
            "Govt.Higher Secondary School \n",
            "2015 – 2017 \n",
            "• \n",
            "SSLC \n",
            "Govt.Higher Secondary School \n",
            "2004 – 2015 \n",
            " \n",
            "STRENGTH & ABILITIES  \n",
            "• \n",
            "Strong analytical and mathematical skills.  \n",
            "• \n",
            "Physically fit and mentally alert.  \n",
            "• \n",
            "Good communication, team player, hardworking and flexible.  \n",
            "    SOFTWARE SKILLS  \n",
            " \n",
            "• \n",
            "Python, Django, HTML, CSS, SQL \n",
            " \n",
            "    CERTIFICATION  \n",
            "  \n",
            "• \n",
            "Attended Online course on Python Django.  \n",
            "PROJECTS  \n",
            " \n",
            "• Login System in Django \n",
            "• Todo app using Django  \n",
            " \n",
            " \n",
            " \n",
            "PERSONAL DETAILS  \n",
            "  \n",
            " Name  \n",
            ": Abijith K   \n",
            " Date of birth              \n",
            "    : 16-06-1999  \n",
            "Father’s Name                                             : Hariharan K  \n",
            "Sex  \n",
            "    : Male  \n",
            "Nationality  \n",
            "                                          : Indian  \n",
            "Marital Status                                             : Single  \n",
            "Languages Known.                                     : English, Malayalam  \n",
            "Hobbies  \n",
            "                                          : Music, Driving, Travelling   \n",
            "Address  \n",
            "                                          : Kunnathadukkath (H)  \n",
            "    Payambra (PO)  \n",
            "          Kozhikode (Dist.)  \n",
            "        Kerala 673571  \n",
            "DECLARATION  \n",
            "I do hereby declare that the particulars furnished above are true and correct to the best of my knowledge \n",
            "and belief.  \n",
            "Yours sincerely,  \n",
            "                                                                                                                                             ABIJITH K  \n",
            "    \n",
            "\n",
            "\n",
            "Answer:\n",
            "The candidate graduated with Bachelor of Commerce in Computer Application in 2020. From their education section, it appears they started working or gaining relevant experience after graduation. Therefore, we can calculate the total work experience by subtracting the year of graduation (2020) from the current year (assuming it is 2023). This gives us 3 years of work experience. However, since the candidate has mentioned attending an online course on Python Django, we can assume some project work or freelance work was done during this period. Without specific dates provided for these projects, we cannot accurately determine the exact number of months of work experience gained through these activities. So, the answer would be approximately 3 years of work experience.\n",
            "Processing resume 4/173\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-58441d41cfab>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_texts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing resume {idx + 1}/{len(resume_texts)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mexperience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_work_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexperience\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total Work Experience for resume {idx + 1}: {experience}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-58441d41cfab>\u001b[0m in \u001b[0;36mextract_work_experience\u001b[0;34m(resume_text)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_work_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwork_experience_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresume_text\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    632\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 )\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[0;32m--> 803\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    804\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             output = (\n\u001b[0;32m--> 657\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/huggingface_pipeline.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0;31m# Process batch of prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             responses = self.pipeline(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0mbatch_prompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mpipeline_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     def preprocess(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                 )\n\u001b[0;32m-> 1224\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# We're out of items within a batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# BS x SL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0;31m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1758\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   1759\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m             \u001b[0;31m# forward pass to get next token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             outputs = self(\n\u001b[0m\u001b[1;32m   2398\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1140\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 )\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1025\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/mistral/modeling_mistral.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mpre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtied_pointers_to_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m                 set_module_tensor_to_device(\n\u001b[0m\u001b[1;32m    348\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\u001b[0m in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    398\u001b[0m                     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mold_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mnew_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required packages\n",
        "!pip install langchain langchain-community\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "import pandas as pd\n",
        "\n",
        "# Load your custom dataset\n",
        "file_path = '/content/extracted_resumes.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Extract the text column\n",
        "resume_texts = df.iloc[:, 1].tolist()\n",
        "\n",
        "# Set up the text generation pipeline\n",
        "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "text_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=5000,\n",
        "    do_sample=False,\n",
        "    repetition_penalty=1.15,\n",
        ")\n",
        "\n",
        "# Use the pipeline with LangChain\n",
        "llm = HuggingFacePipeline(pipeline=text_pipeline, model_kwargs={\"temperature\": 0.1})\n",
        "\n",
        "# Define the prompt template for extracting total work experience\n",
        "work_experience_prompt_tpl = \"\"\"\n",
        "From the Resume text below, calculate the total work experience of the candidate. The result should be in years and months.\n",
        "Question: Calculate the total work experience for the text below -\n",
        "\n",
        "{text}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Create the chain for work experience extraction\n",
        "work_experience_prompt_template = PromptTemplate(template=work_experience_prompt_tpl, input_variables=['text'])\n",
        "work_experience_chain = LLMChain(llm=llm, prompt=work_experience_prompt_template)\n",
        "\n",
        "# Function to extract work experience from resume text\n",
        "def extract_work_experience(resume_text):\n",
        "    try:\n",
        "        result = work_experience_chain.invoke({\"text\": resume_text})\n",
        "        return result['text']\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing resume: {e}\")\n",
        "        return None\n",
        "\n",
        "# Run the extraction on all resumes and print the results\n",
        "for idx, text in enumerate(resume_texts):\n",
        "    print(f\"Processing resume {idx + 1}/{len(resume_texts)}\")\n",
        "    experience = extract_work_experience(text)\n",
        "    if experience:\n",
        "        print(f\"Total Work Experience for resume {idx + 1}: {experience}\")\n",
        "    else:\n",
        "        print(f\"Failed to extract work experience for resume {idx + 1}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ-frUtRTpyl",
        "outputId": "60e216a3-1025-4c8f-ba31-4256f4d89016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.82)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing resume 1/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 112.00 MiB. GPU \n",
            "Failed to extract work experience for resume 1\n",
            "Processing resume 2/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n",
            "Failed to extract work experience for resume 2\n",
            "Processing resume 3/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n",
            "Failed to extract work experience for resume 3\n",
            "Processing resume 4/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 58.00 MiB. GPU \n",
            "Failed to extract work experience for resume 4\n",
            "Processing resume 5/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n",
            "Failed to extract work experience for resume 5\n",
            "Processing resume 6/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n",
            "Failed to extract work experience for resume 6\n",
            "Processing resume 7/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n",
            "Failed to extract work experience for resume 7\n",
            "Processing resume 8/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n",
            "Failed to extract work experience for resume 8\n",
            "Processing resume 9/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n",
            "Failed to extract work experience for resume 9\n",
            "Processing resume 10/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 62.00 MiB. GPU \n",
            "Failed to extract work experience for resume 10\n",
            "Processing resume 11/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 256.00 MiB. GPU \n",
            "Failed to extract work experience for resume 11\n",
            "Processing resume 12/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 112.00 MiB. GPU \n",
            "Failed to extract work experience for resume 12\n",
            "Processing resume 13/173\n",
            "Error processing resume: CUDA out of memory. Tried to allocate 130.00 MiB. GPU \n",
            "Failed to extract work experience for resume 13\n",
            "Processing resume 14/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 112.00 MiB. GPU \n",
            "Failed to extract work experience for resume 14\n",
            "Processing resume 15/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing resume: CUDA out of memory. Tried to allocate 112.00 MiB. GPU \n",
            "Failed to extract work experience for resume 15\n",
            "Processing resume 16/173\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Work Experience for resume 16: \n",
            "From the Resume text below, calculate the total work experience of the candidate. The result should be in years and months.\n",
            "Question: Calculate the total work experience for the text below -\n",
            "\n",
            "nan\n",
            "\n",
            "Answer:\n",
            "The given resume does not contain any work experience details. Therefore, it is impossible to calculate the total work experience.\n",
            "Processing resume 17/173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EsQFE4nqTrN3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}